{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install yfinance\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import statistics as stats\n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()\n",
        "\n",
        "# import sys\n",
        "# !{sys.executable} -m pip install pyportfolioopt\n",
        "! pip install pyportfolioopt\n",
        "from pypfopt import risk_models\n",
        "from pypfopt import expected_returns\n",
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "\n",
        "#Helper function to generate input data of appropriate shape\n",
        "def generate_time_series_data(data, batch_size):\n",
        "  # Generate batches of data\n",
        "  num_samples = data.shape[0]\n",
        "  num_batches = num_samples // batch_size\n",
        "  batchSet = []\n",
        "  for i in range(num_batches):\n",
        "    batchSet.append(data[i * batch_size:(i + 1) * batch_size])\n",
        "  return np.asarray(batchSet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCPoBjxo34Qy",
        "outputId": "4c204aaa-5d4b-4871-fb4d-9319f8ea241e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.8/dist-packages (0.1.90)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.22.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.8/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.8/dist-packages (from yfinance) (2.28.1)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.8/dist-packages (from yfinance) (4.9.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.0->yfinance) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.3.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyportfolioopt in /usr/local/lib/python3.8/dist-packages (1.5.4)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.4 in /usr/local/lib/python3.8/dist-packages (from pyportfolioopt) (1.22.4)\n",
            "Requirement already satisfied: scipy<2.0,>=1.3 in /usr/local/lib/python3.8/dist-packages (from pyportfolioopt) (1.7.3)\n",
            "Requirement already satisfied: cvxpy<2.0.0,>=1.1.10 in /usr/local/lib/python3.8/dist-packages (from pyportfolioopt) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.8/dist-packages (from pyportfolioopt) (1.3.5)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from cvxpy<2.0.0,>=1.1.10->pyportfolioopt) (0.6.2.post0)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.8/dist-packages (from cvxpy<2.0.0,>=1.1.10->pyportfolioopt) (2.0.10)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.8/dist-packages (from cvxpy<2.0.0,>=1.1.10->pyportfolioopt) (3.2.2)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.8/dist-packages (from osqp>=0.4.1->cvxpy<2.0.0,>=1.1.10->pyportfolioopt) (0.1.5.post2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19->pyportfolioopt) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19->pyportfolioopt) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=0.19->pyportfolioopt) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data and create portfolios\n",
        "Portfolio_tickers = ['AVGO', 'COST', 'FDS', 'FTNT', 'ORLY', 'REGN', 'TMO', 'TSLA', 'UNH', 'CPB', 'K']\n",
        "Portfolio = yf.download(Portfolio_tickers, start='2021-05-03', end='2022-07-12')['Adj Close']\n",
        "Portfolio.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "TU82W4EJ363r",
        "outputId": "eec7937d-26d5-4cae-c15e-285c23fbcc9e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  11 of 11 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  AVGO        COST        CPB         FDS       FTNT  \\\n",
              "Date                                                                   \n",
              "2021-05-03  430.409454  375.486542  46.084919  337.009125  40.636002   \n",
              "2021-05-04  425.054901  371.497253  45.942089  340.496826  41.355999   \n",
              "2021-05-05  424.376038  368.735443  46.513390  331.580475  41.875999   \n",
              "2021-05-06  428.917816  378.891785  47.436996  333.068176  41.301998   \n",
              "2021-05-07  432.742523  380.436005  47.179909  332.073059  42.354000   \n",
              "\n",
              "                    K        ORLY        REGN         TMO        TSLA  \\\n",
              "Date                                                                    \n",
              "2021-05-03  59.184650  554.960022  488.619995  465.684540  228.300003   \n",
              "2021-05-04  58.798801  559.880005  485.179993  463.592163  224.533340   \n",
              "2021-05-05  59.354038  560.090027  482.420013  466.073090  223.646667   \n",
              "2021-05-06  63.551258  561.219971  498.679993  468.434509  221.179993   \n",
              "2021-05-07  63.005432  562.320007  496.750000  466.750641  224.123337   \n",
              "\n",
              "                   UNH  \n",
              "Date                    \n",
              "2021-05-03  396.614746  \n",
              "2021-05-04  401.930267  \n",
              "2021-05-05  403.063751  \n",
              "2021-05-06  405.477234  \n",
              "2021-05-07  408.095947  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3e82e1a-ad92-45c5-8479-b7f918323027\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AVGO</th>\n",
              "      <th>COST</th>\n",
              "      <th>CPB</th>\n",
              "      <th>FDS</th>\n",
              "      <th>FTNT</th>\n",
              "      <th>K</th>\n",
              "      <th>ORLY</th>\n",
              "      <th>REGN</th>\n",
              "      <th>TMO</th>\n",
              "      <th>TSLA</th>\n",
              "      <th>UNH</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-05-03</th>\n",
              "      <td>430.409454</td>\n",
              "      <td>375.486542</td>\n",
              "      <td>46.084919</td>\n",
              "      <td>337.009125</td>\n",
              "      <td>40.636002</td>\n",
              "      <td>59.184650</td>\n",
              "      <td>554.960022</td>\n",
              "      <td>488.619995</td>\n",
              "      <td>465.684540</td>\n",
              "      <td>228.300003</td>\n",
              "      <td>396.614746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-04</th>\n",
              "      <td>425.054901</td>\n",
              "      <td>371.497253</td>\n",
              "      <td>45.942089</td>\n",
              "      <td>340.496826</td>\n",
              "      <td>41.355999</td>\n",
              "      <td>58.798801</td>\n",
              "      <td>559.880005</td>\n",
              "      <td>485.179993</td>\n",
              "      <td>463.592163</td>\n",
              "      <td>224.533340</td>\n",
              "      <td>401.930267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-05</th>\n",
              "      <td>424.376038</td>\n",
              "      <td>368.735443</td>\n",
              "      <td>46.513390</td>\n",
              "      <td>331.580475</td>\n",
              "      <td>41.875999</td>\n",
              "      <td>59.354038</td>\n",
              "      <td>560.090027</td>\n",
              "      <td>482.420013</td>\n",
              "      <td>466.073090</td>\n",
              "      <td>223.646667</td>\n",
              "      <td>403.063751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-06</th>\n",
              "      <td>428.917816</td>\n",
              "      <td>378.891785</td>\n",
              "      <td>47.436996</td>\n",
              "      <td>333.068176</td>\n",
              "      <td>41.301998</td>\n",
              "      <td>63.551258</td>\n",
              "      <td>561.219971</td>\n",
              "      <td>498.679993</td>\n",
              "      <td>468.434509</td>\n",
              "      <td>221.179993</td>\n",
              "      <td>405.477234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-07</th>\n",
              "      <td>432.742523</td>\n",
              "      <td>380.436005</td>\n",
              "      <td>47.179909</td>\n",
              "      <td>332.073059</td>\n",
              "      <td>42.354000</td>\n",
              "      <td>63.005432</td>\n",
              "      <td>562.320007</td>\n",
              "      <td>496.750000</td>\n",
              "      <td>466.750641</td>\n",
              "      <td>224.123337</td>\n",
              "      <td>408.095947</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3e82e1a-ad92-45c5-8479-b7f918323027')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f3e82e1a-ad92-45c5-8479-b7f918323027 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f3e82e1a-ad92-45c5-8479-b7f918323027');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 60\n",
        "\n",
        "#Data preprocessing\n",
        "training_data_len = math.ceil(len(Portfolio)* 0.8)\n",
        "temp = []\n",
        "tickers = Portfolio.columns.values\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_data = scaler.fit_transform(Portfolio)\n",
        "data = scaled_data.reshape(-1,11)\n",
        "print(f\"data shape: {data.shape}\")\n",
        "\n",
        "#Training data\n",
        "train_data = scaled_data[0: training_data_len, :]\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(batch_size, len(train_data)):\n",
        "    x_train.append(train_data[i-batch_size:i, :])\n",
        "    y_train.append(train_data[i, :])\n",
        "\n",
        "x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], x_train.shape[2]))\n",
        "print(f\"train_data shape: {train_data.shape}\")\n",
        "print(f\"x_train shape: {x_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "\n",
        "#Test data\n",
        "test_data = scaled_data[training_data_len-batch_size: , : ]\n",
        "y_test = data[training_data_len:]\n",
        "x_test = []\n",
        "\n",
        "for i in range(batch_size, len(test_data)):\n",
        "  x_test.append(test_data[i-batch_size:i, :])\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], x_test.shape[2]))\n",
        "\n",
        "print(f\"test data shape: {test_data.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJpW0BoU4eI5",
        "outputId": "08fcb82e-b94c-4916-c7cf-6bc1ae67b2ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data shape: (300, 11)\n",
            "train_data shape: (240, 11)\n",
            "x_train shape: (180, 60, 11)\n",
            "y_train shape: (180, 11)\n",
            "test data shape: (120, 11)\n",
            "x_test shape: (60, 60, 11)\n",
            "y_test shape: (60, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set the hyperparameters\n",
        "latent_dim = 32\n",
        "learning_rate = 1e-2\n",
        "num_epochs = 50\n",
        "beta = 1 #information bottleneck coefficient\n",
        "n_stocks = np.shape(x_train)[2]\n",
        "\n",
        "#Split the data into training and test sets\n",
        "# x_train, x_test, y_train, y_test = train_test_split(dataStocks, dataSPY, test_size=0.2)\n",
        "# x_train = generate_time_series_data(x_train, batch_size)\n",
        "# x_test = generate_time_series_data(x_test, batch_size)\n",
        "# y_train = generate_time_series_data(y_train, batch_size)\n",
        "# y_test = generate_time_series_data(y_test, batch_size)\n",
        "# print(f\"shapes 1: {np.shape(x_train)} and {np.shape(y_train)}\")\n",
        "\n",
        "#Reshape the data to be 3D [samples, timesteps, features]\n",
        "# x_train = x_train.reshape((-1, 1, 1))\n",
        "# x_test = x_test.reshape(-1, 1, 1)\n",
        "\n",
        "#Build the model\n",
        "inputs = tf.keras.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
        "lstm_encoder = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = lstm_encoder(inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "z_mean = tf.keras.layers.Dense(latent_dim)(encoder_outputs)\n",
        "z_log_var = tf.keras.layers.Dense(latent_dim)(encoder_outputs)\n",
        "\n",
        "def sampling(args):\n",
        "  z_mean, z_log_var = args\n",
        "  epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "  return z_mean + tf.exp(0.5*z_log_var)*epsilon\n",
        "\n",
        "z = tf.keras.layers.Lambda(sampling)([z_mean, z_log_var])\n",
        "\n",
        "lstm_decoder = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = lstm_decoder(z, initial_state=encoder_states)\n",
        "decoder_outputs=tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_stocks))(decoder_outputs)\n",
        "\n",
        "#Define the losses for IB and no-IB\n",
        "def IBLoss(inputs, decoder_outputs):\n",
        "  reconstruction_loss = tf.keras.losses.MeanSquaredError()(inputs, decoder_outputs)\n",
        "  kl_loss = -0.5*tf.reduce_mean(z_log_var - tf.square(z_mean)-tf.exp(z_log_var) + 1)\n",
        "  information_bottleneck_loss = beta*kl_loss\n",
        "  loss = reconstruction_loss + information_bottleneck_loss\n",
        "  return loss\n",
        "\n",
        "def MSELoss(inputs, decoder_outputs):\n",
        "  reconstruction_loss = tf.keras.losses.MeanSquaredError()(inputs, decoder_outputs)\n",
        "  return reconstruction_loss\n",
        "\n",
        "#Define the optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "#Compile the model\n",
        "model = tf.keras.Model(inputs, decoder_outputs)\n",
        "model.compile(optimizer=optimizer, loss=IBLoss)\n",
        "\n",
        "model2 = tf.keras.Model(inputs, decoder_outputs)\n",
        "model2.compile(optimizer=optimizer, loss=MSELoss)\n",
        "\n",
        "#Train the model\n",
        "model.fit(x_train, y_train, batch_size=1, epochs=num_epochs)\n",
        "model2.fit(x_train, y_train, batch_size=1, epochs=num_epochs)\n",
        "\n",
        "#Evaluate the model\n",
        "predictions = np.mean(model.predict(x_test), axis=0)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
        "\n",
        "predictions2 = np.mean(model2.predict(x_test), axis=0)\n",
        "predictions2 = scaler.inverse_transform(predictions2)\n",
        "rmse2 = np.sqrt(np.mean(predictions2 - y_test)**2)\n",
        "\n",
        "print(f\"IB rmse: {rmse}\")\n",
        "print(f\"no IB rmse: {rmse2}\")\n",
        "\n",
        "# test_loss = model.evaluate(x_test, y_test)\n",
        "# print(f'Test loss: {test_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n96j-aiS4h1u",
        "outputId": "ea69e7cd-e6c8-4402-cbfa-899537ace69a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 180 samples\n",
            "Epoch 1/50\n",
            "180/180 [==============================] - 18s 80ms/sample - loss: 0.0505\n",
            "Epoch 2/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0284\n",
            "Epoch 3/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0235\n",
            "Epoch 4/50\n",
            "180/180 [==============================] - 14s 78ms/sample - loss: 0.0206\n",
            "Epoch 5/50\n",
            "180/180 [==============================] - 14s 80ms/sample - loss: 0.0191\n",
            "Epoch 6/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0182\n",
            "Epoch 7/50\n",
            "180/180 [==============================] - 14s 78ms/sample - loss: 0.0178\n",
            "Epoch 8/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0147\n",
            "Epoch 9/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0138\n",
            "Epoch 10/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0138\n",
            "Epoch 11/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0144\n",
            "Epoch 12/50\n",
            "180/180 [==============================] - 14s 80ms/sample - loss: 0.0137\n",
            "Epoch 13/50\n",
            "180/180 [==============================] - 14s 80ms/sample - loss: 0.0119\n",
            "Epoch 14/50\n",
            "180/180 [==============================] - 14s 80ms/sample - loss: 0.0099\n",
            "Epoch 15/50\n",
            "180/180 [==============================] - 15s 85ms/sample - loss: 0.0097\n",
            "Epoch 16/50\n",
            "180/180 [==============================] - 15s 81ms/sample - loss: 0.0101\n",
            "Epoch 17/50\n",
            "180/180 [==============================] - 15s 83ms/sample - loss: 0.0096\n",
            "Epoch 18/50\n",
            "180/180 [==============================] - 15s 82ms/sample - loss: 0.0094\n",
            "Epoch 19/50\n",
            "180/180 [==============================] - 15s 82ms/sample - loss: 0.0096\n",
            "Epoch 20/50\n",
            "180/180 [==============================] - 15s 82ms/sample - loss: 0.0090\n",
            "Epoch 21/50\n",
            "180/180 [==============================] - 14s 80ms/sample - loss: 0.0094\n",
            "Epoch 22/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0095\n",
            "Epoch 23/50\n",
            "180/180 [==============================] - 14s 78ms/sample - loss: 0.0089\n",
            "Epoch 24/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0094\n",
            "Epoch 25/50\n",
            "180/180 [==============================] - 15s 82ms/sample - loss: 0.0095\n",
            "Epoch 26/50\n",
            "180/180 [==============================] - 15s 82ms/sample - loss: 0.0086\n",
            "Epoch 27/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0087\n",
            "Epoch 28/50\n",
            "180/180 [==============================] - 15s 81ms/sample - loss: 0.0088\n",
            "Epoch 29/50\n",
            "180/180 [==============================] - 15s 81ms/sample - loss: 0.0089\n",
            "Epoch 30/50\n",
            "180/180 [==============================] - 15s 81ms/sample - loss: 0.0088\n",
            "Epoch 31/50\n",
            "180/180 [==============================] - 15s 85ms/sample - loss: 0.0092\n",
            "Epoch 32/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0085\n",
            "Epoch 33/50\n",
            "180/180 [==============================] - 15s 81ms/sample - loss: 0.0089\n",
            "Epoch 34/50\n",
            "180/180 [==============================] - 15s 85ms/sample - loss: 0.0086\n",
            "Epoch 35/50\n",
            "180/180 [==============================] - 14s 80ms/sample - loss: 0.0096\n",
            "Epoch 36/50\n",
            "180/180 [==============================] - 15s 83ms/sample - loss: 0.0091\n",
            "Epoch 37/50\n",
            "180/180 [==============================] - 14s 78ms/sample - loss: 0.0085\n",
            "Epoch 38/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0083\n",
            "Epoch 39/50\n",
            "180/180 [==============================] - 14s 80ms/sample - loss: 0.0081\n",
            "Epoch 40/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0081\n",
            "Epoch 41/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0078\n",
            "Epoch 42/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0081\n",
            "Epoch 43/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0076\n",
            "Epoch 44/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0088\n",
            "Epoch 45/50\n",
            "180/180 [==============================] - 14s 78ms/sample - loss: 0.0070\n",
            "Epoch 46/50\n",
            "180/180 [==============================] - 14s 78ms/sample - loss: 0.0062\n",
            "Epoch 47/50\n",
            "180/180 [==============================] - 14s 78ms/sample - loss: 0.0075\n",
            "Epoch 48/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0063\n",
            "Epoch 49/50\n",
            "180/180 [==============================] - 14s 80ms/sample - loss: 0.0058\n",
            "Epoch 50/50\n",
            "180/180 [==============================] - 14s 79ms/sample - loss: 0.0060\n",
            "Train on 180 samples\n",
            "Epoch 1/50\n",
            "180/180 [==============================] - 33s 177ms/sample - loss: 0.0058\n",
            "Epoch 2/50\n",
            "180/180 [==============================] - 33s 181ms/sample - loss: 0.0058\n",
            "Epoch 3/50\n",
            "180/180 [==============================] - 32s 178ms/sample - loss: 0.0053\n",
            "Epoch 4/50\n",
            "180/180 [==============================] - 32s 180ms/sample - loss: 0.0057\n",
            "Epoch 5/50\n",
            "180/180 [==============================] - 32s 179ms/sample - loss: 0.0054\n",
            "Epoch 6/50\n",
            "180/180 [==============================] - 32s 180ms/sample - loss: 0.0052\n",
            "Epoch 7/50\n",
            "180/180 [==============================] - 32s 180ms/sample - loss: 0.0053\n",
            "Epoch 8/50\n",
            "180/180 [==============================] - 32s 177ms/sample - loss: 0.0053\n",
            "Epoch 9/50\n",
            "180/180 [==============================] - 32s 178ms/sample - loss: 0.0053\n",
            "Epoch 10/50\n",
            "180/180 [==============================] - 32s 178ms/sample - loss: 0.0049\n",
            "Epoch 11/50\n",
            "180/180 [==============================] - 32s 177ms/sample - loss: 0.0048\n",
            "Epoch 12/50\n",
            "180/180 [==============================] - 32s 177ms/sample - loss: 0.0048\n",
            "Epoch 13/50\n",
            "180/180 [==============================] - 32s 178ms/sample - loss: 0.0047\n",
            "Epoch 14/50\n",
            "180/180 [==============================] - 32s 179ms/sample - loss: 0.0047\n",
            "Epoch 15/50\n",
            "180/180 [==============================] - 32s 180ms/sample - loss: 0.0045\n",
            "Epoch 16/50\n",
            "180/180 [==============================] - 32s 179ms/sample - loss: 0.0043\n",
            "Epoch 17/50\n",
            "180/180 [==============================] - 33s 182ms/sample - loss: 0.0046\n",
            "Epoch 18/50\n",
            "180/180 [==============================] - 32s 179ms/sample - loss: 0.0044\n",
            "Epoch 19/50\n",
            "180/180 [==============================] - 32s 178ms/sample - loss: 0.0046\n",
            "Epoch 20/50\n",
            "180/180 [==============================] - 32s 179ms/sample - loss: 0.0041\n",
            "Epoch 21/50\n",
            "180/180 [==============================] - 32s 179ms/sample - loss: 0.0046\n",
            "Epoch 22/50\n",
            "180/180 [==============================] - 32s 179ms/sample - loss: 0.0041\n",
            "Epoch 23/50\n",
            "180/180 [==============================] - 32s 179ms/sample - loss: 0.0038\n",
            "Epoch 24/50\n",
            "180/180 [==============================] - 32s 180ms/sample - loss: 0.0038\n",
            "Epoch 25/50\n",
            "180/180 [==============================] - 32s 180ms/sample - loss: 0.0035\n",
            "Epoch 26/50\n",
            "180/180 [==============================] - 32s 179ms/sample - loss: 0.0038\n",
            "Epoch 27/50\n",
            "180/180 [==============================] - 33s 181ms/sample - loss: 0.0038\n",
            "Epoch 28/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0035\n",
            "Epoch 29/50\n",
            "180/180 [==============================] - 34s 187ms/sample - loss: 0.0037\n",
            "Epoch 30/50\n",
            "180/180 [==============================] - 34s 187ms/sample - loss: 0.0034\n",
            "Epoch 31/50\n",
            "180/180 [==============================] - 33s 186ms/sample - loss: 0.0031\n",
            "Epoch 32/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0032\n",
            "Epoch 33/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0030\n",
            "Epoch 34/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0029\n",
            "Epoch 35/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0030\n",
            "Epoch 36/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0031\n",
            "Epoch 37/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0028\n",
            "Epoch 38/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0028\n",
            "Epoch 39/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0029\n",
            "Epoch 40/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0027\n",
            "Epoch 41/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0026\n",
            "Epoch 42/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0028\n",
            "Epoch 43/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0029\n",
            "Epoch 44/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0027\n",
            "Epoch 45/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0025\n",
            "Epoch 46/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0028\n",
            "Epoch 47/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0028\n",
            "Epoch 48/50\n",
            "180/180 [==============================] - 33s 186ms/sample - loss: 0.0026\n",
            "Epoch 49/50\n",
            "180/180 [==============================] - 34s 186ms/sample - loss: 0.0027\n",
            "Epoch 50/50\n",
            "180/180 [==============================] - 33s 185ms/sample - loss: 0.0024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IB rmse: 377.39625257736736\n",
            "no IB rmse: 377.4073726742098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhGyizQH93qP",
        "outputId": "2bc895a5-b191-4c6e-82a2-c86284c3c9c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 5313116654802279898\n",
              " xla_global_id: -1, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 40231960576\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 13740885530245362191\n",
              " physical_device_desc: \"device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\"\n",
              " xla_global_id: 416903419]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicted stock prices with two models\n",
        "Port_1 = pd.DataFrame(predictions, columns = Portfolio_tickers)\n",
        "Port_2 = pd.DataFrame(predictions, columns = Portfolio_tickers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvXWsz_y7Cb5",
        "outputId": "7df1e3ea-fca9-4240-823e-af8116c368ef"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  11 of 11 completed\n",
            "60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calcSharpe(port):\n",
        "  mu = expected_returns.capm_return(port)\n",
        "  Sigma = risk_models.CovarianceShrinkage(port).ledoit_wolf()\n",
        "\n",
        "  ef = EfficientFrontier(mu, Sigma)\n",
        "  ef.max_sharpe()\n",
        "  weights = ef.clean_weights()\n",
        "\n",
        "  portfolio_mean = 0\n",
        "  portfolio_var = 0\n",
        "\n",
        "  for ticker in weights.keys():\n",
        "      portfolio_mean += weights[ticker]*mu[ticker]\n",
        "\n",
        "  for ticker1 in weights.keys():\n",
        "      for ticker2 in weights.keys():\n",
        "          portfolio_var += weights[ticker1]*weights[ticker2]*Sigma[ticker1][ticker2]\n",
        "\n",
        "  portfolio_std = portfolio_var ** (1/2)\n",
        "\n",
        "  portfolio_sharpe = portfolio_mean/portfolio_std\n",
        "  return portfolio_sharpe\n",
        "     "
      ],
      "metadata": {
        "id": "kNJ9v8pf5h5l"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sharpe Ratios\\nPortfolio with IB: {calcSharpe(Port_1)}\\nPortfolio without IB: {calcSharpe(Port_2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez8fTdKn5_pH",
        "outputId": "77cdde93-3731-4de0-f79f-df6e2e4f8f83"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sharpe Ratios\n",
            "Portfolio with IB: 9.497522368882235\n",
            "Portfolio without IB: 9.497522368882235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zza-YS6zGLPL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}