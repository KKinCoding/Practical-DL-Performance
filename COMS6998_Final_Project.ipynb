{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Dukk4KNxBb-p",
        "outputId": "898d51c9-9711-4dc2-f377-5ccf4e632056"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "CRjkr4X0e1az"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "dataSPY = yf.download(  # or pdr.get_data_yahoo(...\n",
        "        # tickers list or string as well\n",
        "        tickers = \"SPY\",\n",
        "\n",
        "        # use \"period\" instead of start/end\n",
        "        # valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
        "        # (optional, default is '1mo')\n",
        "        period = \"10y\",\n",
        "\n",
        "        # fetch data by interval (including intraday if period < 60 days)\n",
        "        # valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
        "        # (optional, default is '1d')\n",
        "        interval = \"1d\",\n",
        "\n",
        "        # Whether to ignore timezone when aligning ticker data from \n",
        "        # different timezones. Default is True. False may be useful for \n",
        "        # minute/hourly data.\n",
        "        ignore_tz = False,\n",
        "\n",
        "        # group by ticker (to access via data['SPY'])\n",
        "        # (optional, default is 'column')\n",
        "        group_by = 'ticker',\n",
        "\n",
        "        # adjust all OHLC automatically\n",
        "        # (optional, default is False)\n",
        "        auto_adjust = True,\n",
        "\n",
        "        # identify and attempt repair of currency unit mixups e.g. $/cents\n",
        "        repair = False,\n",
        "\n",
        "        # download pre/post regular market hours data\n",
        "        # (optional, default is False)\n",
        "        prepost = True,\n",
        "\n",
        "        # use threads for mass downloading? (True/False/Integer)\n",
        "        # (optional, default is True)\n",
        "        threads = True,\n",
        "\n",
        "        # proxy URL scheme use use when downloading?\n",
        "        # (optional, default is None)\n",
        "        proxy = None\n",
        "    )['Close']\n",
        "dataStocks = []\n",
        "for stock in ['AAPL', 'MSFT']:\n",
        "\n",
        "  dataStocks.append(\n",
        "        yf.download(  # or pdr.get_data_yahoo(...\n",
        "        # tickers list or string as well\n",
        "        tickers = stock,\n",
        "\n",
        "        # use \"period\" instead of start/end\n",
        "        # valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
        "        # (optional, default is '1mo')\n",
        "        period = \"10y\",\n",
        "\n",
        "        # fetch data by interval (including intraday if period < 60 days)\n",
        "        # valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
        "        # (optional, default is '1d')\n",
        "        interval = \"1d\",\n",
        "\n",
        "        # Whether to ignore timezone when aligning ticker data from \n",
        "        # different timezones. Default is True. False may be useful for \n",
        "        # minute/hourly data.\n",
        "        ignore_tz = False,\n",
        "\n",
        "        # group by ticker (to access via data['SPY'])\n",
        "        # (optional, default is 'column')\n",
        "        group_by = 'ticker',\n",
        "\n",
        "        # adjust all OHLC automatically\n",
        "        # (optional, default is False)\n",
        "        auto_adjust = True,\n",
        "\n",
        "        # identify and attempt repair of currency unit mixups e.g. $/cents\n",
        "        repair = False,\n",
        "\n",
        "        # download pre/post regular market hours data\n",
        "        # (optional, default is False)\n",
        "        prepost = True,\n",
        "\n",
        "        # use threads for mass downloading? (True/False/Integer)\n",
        "        # (optional, default is True)\n",
        "        threads = True,\n",
        "\n",
        "        # proxy URL scheme use use when downloading?\n",
        "        # (optional, default is None)\n",
        "        proxy = None\n",
        "    )['Close']\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C4iAdXtfOx6",
        "outputId": "b38dbae9-bb66-4ea3-8d8b-ba9e868ec2ca"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataStocks = np.transpose(dataStocks) #reorder so 0th dimension is time, 1st dimension is features\n",
        "print(f\"Stocks data shape: {np.shape(dataStocks)}\")\n",
        "print(f\"SPY data shape: {np.shape(dataSPY)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azP9De7T6f0F",
        "outputId": "230d2085-da3a-47d6-bb87-875c16de36ab"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stocks data shape: (2519, 2)\n",
            "SPY data shape: (2519,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()"
      ],
      "metadata": {
        "id": "kV2VwzH_0abd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjQagAz1epXl",
        "outputId": "e80ae551-3d50-403a-986f-4f9b4c83d2ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shapes 1: (15, 128, 2) and (15, 128)\n",
            "test: 128 and 2\n",
            "shapes 2: (None, 128, 2) and (None, 128, 32)\n",
            "shapes 2: (None, 128, 2) and (None, 128)\n",
            "Tensor(\"Squeeze_6:0\", shape=(None, 128), dtype=float32)\n",
            "Tensor(\"input_40:0\", shape=(None, 128, 2), dtype=float32)\n",
            "inputs: Tensor(\"tf_op_layer_Squeeze_6_target:0\", shape=(None, None), dtype=float32)\n",
            "Tensor(\"Squeeze_6:0\", shape=(None, 128), dtype=float32)\n",
            "shapes 3: (None, None) and (None, 128)\n",
            "shapes 4: ()\n",
            "Train on 15 samples\n",
            "Epoch 1/1000\n",
            "15/15 [==============================] - 9s 606ms/sample - loss: 73254.5469\n",
            "Epoch 2/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 71018.9609\n",
            "Epoch 3/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 69394.9844\n",
            "Epoch 4/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 68321.0703\n",
            "Epoch 5/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 67271.3984\n",
            "Epoch 6/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 66216.3750\n",
            "Epoch 7/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 65148.0039\n",
            "Epoch 8/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 64072.6211\n",
            "Epoch 9/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 62996.4961\n",
            "Epoch 10/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 61922.7539\n",
            "Epoch 11/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 60854.2656\n",
            "Epoch 12/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 59792.9961\n",
            "Epoch 13/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 58740.3867\n",
            "Epoch 14/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 57697.5625\n",
            "Epoch 15/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 56665.4023\n",
            "Epoch 16/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 55644.6055\n",
            "Epoch 17/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 54635.4688\n",
            "Epoch 18/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 53526.6719\n",
            "Epoch 19/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 52522.4570\n",
            "Epoch 20/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 51534.6133\n",
            "Epoch 21/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 50556.8125\n",
            "Epoch 22/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 49590.3828\n",
            "Epoch 23/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 48636.2305\n",
            "Epoch 24/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 47695.0312\n",
            "Epoch 25/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 46767.2852\n",
            "Epoch 26/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 45853.3789\n",
            "Epoch 27/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 44953.6172\n",
            "Epoch 28/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 44068.2227\n",
            "Epoch 29/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 43197.3828\n",
            "Epoch 30/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 42341.2070\n",
            "Epoch 31/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 41499.7969\n",
            "Epoch 32/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 40673.1875\n",
            "Epoch 33/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 39861.4219\n",
            "Epoch 34/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 39064.4883\n",
            "Epoch 35/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 38282.3633\n",
            "Epoch 36/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 37515.0078\n",
            "Epoch 37/1000\n",
            "15/15 [==============================] - 0s 5ms/sample - loss: 36762.3750\n",
            "Epoch 38/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 36024.3711\n",
            "Epoch 39/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 35300.9180\n",
            "Epoch 40/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 34591.9141\n",
            "Epoch 41/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 33897.2617\n",
            "Epoch 42/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 33216.8242\n",
            "Epoch 43/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 32550.4805\n",
            "Epoch 44/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 31898.0879\n",
            "Epoch 45/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 31259.5215\n",
            "Epoch 46/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 30634.6133\n",
            "Epoch 47/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 30023.2227\n",
            "Epoch 48/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 29425.1816\n",
            "Epoch 49/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 28840.3398\n",
            "Epoch 50/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 28268.5195\n",
            "Epoch 51/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 27709.5566\n",
            "Epoch 52/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 27163.2754\n",
            "Epoch 53/1000\n",
            "15/15 [==============================] - 0s 5ms/sample - loss: 26629.5059\n",
            "Epoch 54/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 26108.0664\n",
            "Epoch 55/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 25598.7891\n",
            "Epoch 56/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 25101.4746\n",
            "Epoch 57/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 24615.9629\n",
            "Epoch 58/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 24142.0586\n",
            "Epoch 59/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 23679.5762\n",
            "Epoch 60/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 23228.3438\n",
            "Epoch 61/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 22788.1758\n",
            "Epoch 62/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 22358.8906\n",
            "Epoch 63/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 21940.2930\n",
            "Epoch 64/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 21532.2090\n",
            "Epoch 65/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 21134.4551\n",
            "Epoch 66/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 20746.8516\n",
            "Epoch 67/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 20369.2129\n",
            "Epoch 68/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 20001.3633\n",
            "Epoch 69/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 19643.1094\n",
            "Epoch 70/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 19294.2871\n",
            "Epoch 71/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 18954.7129\n",
            "Epoch 72/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 18624.2188\n",
            "Epoch 73/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 18302.6152\n",
            "Epoch 74/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 17989.7305\n",
            "Epoch 75/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 17685.4023\n",
            "Epoch 76/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 17389.4492\n",
            "Epoch 77/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 17101.7051\n",
            "Epoch 78/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 16822.0000\n",
            "Epoch 79/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 16550.1680\n",
            "Epoch 80/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 16286.0459\n",
            "Epoch 81/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 16029.4658\n",
            "Epoch 82/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 15780.2646\n",
            "Epoch 83/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 15538.2920\n",
            "Epoch 84/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 15303.3799\n",
            "Epoch 85/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 15075.3779\n",
            "Epoch 86/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 14854.1230\n",
            "Epoch 87/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 14639.4736\n",
            "Epoch 88/1000\n",
            "15/15 [==============================] - 0s 5ms/sample - loss: 14431.2715\n",
            "Epoch 89/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 14229.3662\n",
            "Epoch 90/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 14033.6133\n",
            "Epoch 91/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 13843.8701\n",
            "Epoch 92/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 13659.9941\n",
            "Epoch 93/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 13481.8379\n",
            "Epoch 94/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 13309.2646\n",
            "Epoch 95/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 13142.1445\n",
            "Epoch 96/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 12980.3311\n",
            "Epoch 97/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 12823.6982\n",
            "Epoch 98/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 12672.1143\n",
            "Epoch 99/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 12525.4502\n",
            "Epoch 100/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 12383.5781\n",
            "Epoch 101/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 12246.3730\n",
            "Epoch 102/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 12113.7158\n",
            "Epoch 103/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 11985.4844\n",
            "Epoch 104/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 11861.5557\n",
            "Epoch 105/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 11741.8184\n",
            "Epoch 106/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 11626.1582\n",
            "Epoch 107/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 11514.4600\n",
            "Epoch 108/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 11406.6162\n",
            "Epoch 109/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 11302.5215\n",
            "Epoch 110/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 11202.0615\n",
            "Epoch 111/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 11105.1387\n",
            "Epoch 112/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 11011.6533\n",
            "Epoch 113/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 10921.4990\n",
            "Epoch 114/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 10834.5811\n",
            "Epoch 115/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 10750.8037\n",
            "Epoch 116/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 10670.0742\n",
            "Epoch 117/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 10592.3018\n",
            "Epoch 118/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 10517.3936\n",
            "Epoch 119/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 10445.2617\n",
            "Epoch 120/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 10375.8242\n",
            "Epoch 121/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 10308.9951\n",
            "Epoch 122/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 10244.6914\n",
            "Epoch 123/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 10182.8330\n",
            "Epoch 124/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 10123.3457\n",
            "Epoch 125/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 10066.1475\n",
            "Epoch 126/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 10011.1680\n",
            "Epoch 127/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9958.3340\n",
            "Epoch 128/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9907.5713\n",
            "Epoch 129/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 9858.8154\n",
            "Epoch 130/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9811.9980\n",
            "Epoch 131/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9767.0527\n",
            "Epoch 132/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9723.9150\n",
            "Epoch 133/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9682.5254\n",
            "Epoch 134/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9642.8203\n",
            "Epoch 135/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9604.7422\n",
            "Epoch 136/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9568.2334\n",
            "Epoch 137/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 9533.2402\n",
            "Epoch 138/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 9499.7070\n",
            "Epoch 139/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9467.5811\n",
            "Epoch 140/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 9436.8096\n",
            "Epoch 141/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 9407.3486\n",
            "Epoch 142/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9379.1445\n",
            "Epoch 143/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9352.1504\n",
            "Epoch 144/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 9326.3262\n",
            "Epoch 145/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9301.6230\n",
            "Epoch 146/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9278.0010\n",
            "Epoch 147/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9255.4180\n",
            "Epoch 148/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 9233.8340\n",
            "Epoch 149/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9213.2090\n",
            "Epoch 150/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9193.5088\n",
            "Epoch 151/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9174.6943\n",
            "Epoch 152/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9156.7314\n",
            "Epoch 153/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9139.5850\n",
            "Epoch 154/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9123.2256\n",
            "Epoch 155/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9107.6172\n",
            "Epoch 156/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9092.7324\n",
            "Epoch 157/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9078.5410\n",
            "Epoch 158/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9065.0127\n",
            "Epoch 159/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 9052.1201\n",
            "Epoch 160/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9039.8389\n",
            "Epoch 161/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9028.1436\n",
            "Epoch 162/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9017.0059\n",
            "Epoch 163/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 9006.4033\n",
            "Epoch 164/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8996.3145\n",
            "Epoch 165/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8986.7158\n",
            "Epoch 166/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8977.5879\n",
            "Epoch 167/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8968.9072\n",
            "Epoch 168/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8960.6562\n",
            "Epoch 169/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8952.8145\n",
            "Epoch 170/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8945.3643\n",
            "Epoch 171/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8938.2891\n",
            "Epoch 172/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8931.5693\n",
            "Epoch 173/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8925.1924\n",
            "Epoch 174/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8919.1387\n",
            "Epoch 175/1000\n",
            "15/15 [==============================] - 0s 5ms/sample - loss: 8913.3975\n",
            "Epoch 176/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8907.9492\n",
            "Epoch 177/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8902.7861\n",
            "Epoch 178/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8897.8906\n",
            "Epoch 179/1000\n",
            "15/15 [==============================] - 0s 5ms/sample - loss: 8893.2510\n",
            "Epoch 180/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8888.8564\n",
            "Epoch 181/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8884.6943\n",
            "Epoch 182/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8880.7529\n",
            "Epoch 183/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8877.0215\n",
            "Epoch 184/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8873.4922\n",
            "Epoch 185/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8870.1514\n",
            "Epoch 186/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8866.9941\n",
            "Epoch 187/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8864.0068\n",
            "Epoch 188/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8861.1836\n",
            "Epoch 189/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8858.5176\n",
            "Epoch 190/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8855.9971\n",
            "Epoch 191/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8853.6172\n",
            "Epoch 192/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8851.3711\n",
            "Epoch 193/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8849.2510\n",
            "Epoch 194/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8847.2510\n",
            "Epoch 195/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8845.3633\n",
            "Epoch 196/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8843.5840\n",
            "Epoch 197/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8841.9062\n",
            "Epoch 198/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8840.3242\n",
            "Epoch 199/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8838.8350\n",
            "Epoch 200/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8837.4316\n",
            "Epoch 201/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8836.1123\n",
            "Epoch 202/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8834.8672\n",
            "Epoch 203/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8833.6973\n",
            "Epoch 204/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8832.5977\n",
            "Epoch 205/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8831.5625\n",
            "Epoch 206/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8830.5889\n",
            "Epoch 207/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8829.6748\n",
            "Epoch 208/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8828.8164\n",
            "Epoch 209/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8828.0088\n",
            "Epoch 210/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8827.2510\n",
            "Epoch 211/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8826.5391\n",
            "Epoch 212/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8825.8730\n",
            "Epoch 213/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8825.2461\n",
            "Epoch 214/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8824.6592\n",
            "Epoch 215/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8824.1094\n",
            "Epoch 216/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8823.5928\n",
            "Epoch 217/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8823.1094\n",
            "Epoch 218/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8822.6572\n",
            "Epoch 219/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8822.2324\n",
            "Epoch 220/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8821.8350\n",
            "Epoch 221/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8821.4639\n",
            "Epoch 222/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8821.1172\n",
            "Epoch 223/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8820.7920\n",
            "Epoch 224/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8820.4883\n",
            "Epoch 225/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8820.2051\n",
            "Epoch 226/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8819.9404\n",
            "Epoch 227/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8819.6934\n",
            "Epoch 228/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8819.4619\n",
            "Epoch 229/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8819.2471\n",
            "Epoch 230/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8819.0469\n",
            "Epoch 231/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8818.8584\n",
            "Epoch 232/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8818.6846\n",
            "Epoch 233/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8818.5205\n",
            "Epoch 234/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8818.3691\n",
            "Epoch 235/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8818.2275\n",
            "Epoch 236/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8818.0967\n",
            "Epoch 237/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8817.9736\n",
            "Epoch 238/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8817.8604\n",
            "Epoch 239/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8817.7539\n",
            "Epoch 240/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8817.6543\n",
            "Epoch 241/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8817.5635\n",
            "Epoch 242/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8817.4775\n",
            "Epoch 243/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8817.3994\n",
            "Epoch 244/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8817.3262\n",
            "Epoch 245/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8817.2578\n",
            "Epoch 246/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8817.1953\n",
            "Epoch 247/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8817.1367\n",
            "Epoch 248/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8817.0820\n",
            "Epoch 249/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8817.0322\n",
            "Epoch 250/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.9863\n",
            "Epoch 251/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.9424\n",
            "Epoch 252/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.9033\n",
            "Epoch 253/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.8662\n",
            "Epoch 254/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.8320\n",
            "Epoch 255/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.7998\n",
            "Epoch 256/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.7705\n",
            "Epoch 257/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.7441\n",
            "Epoch 258/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.7188\n",
            "Epoch 259/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.6953\n",
            "Epoch 260/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.6738\n",
            "Epoch 261/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.6553\n",
            "Epoch 262/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.6377\n",
            "Epoch 263/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.6221\n",
            "Epoch 264/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.6064\n",
            "Epoch 265/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.5918\n",
            "Epoch 266/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.5781\n",
            "Epoch 267/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.5664\n",
            "Epoch 268/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.5547\n",
            "Epoch 269/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.5459\n",
            "Epoch 270/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.5361\n",
            "Epoch 271/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.5283\n",
            "Epoch 272/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.5195\n",
            "Epoch 273/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.5127\n",
            "Epoch 274/1000\n",
            "15/15 [==============================] - 0s 5ms/sample - loss: 8816.5059\n",
            "Epoch 275/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.5010\n",
            "Epoch 276/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4951\n",
            "Epoch 277/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4893\n",
            "Epoch 278/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4844\n",
            "Epoch 279/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4805\n",
            "Epoch 280/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4756\n",
            "Epoch 281/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4727\n",
            "Epoch 282/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4688\n",
            "Epoch 283/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4668\n",
            "Epoch 284/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4639\n",
            "Epoch 285/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4609\n",
            "Epoch 286/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4580\n",
            "Epoch 287/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4570\n",
            "Epoch 288/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4551\n",
            "Epoch 289/1000\n",
            "15/15 [==============================] - 0s 5ms/sample - loss: 8816.4531\n",
            "Epoch 290/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4521\n",
            "Epoch 291/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4502\n",
            "Epoch 292/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4492\n",
            "Epoch 293/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4482\n",
            "Epoch 294/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4473\n",
            "Epoch 295/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4443\n",
            "Epoch 296/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4443\n",
            "Epoch 297/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4424\n",
            "Epoch 298/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4424\n",
            "Epoch 299/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4414\n",
            "Epoch 300/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4404\n",
            "Epoch 301/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4404\n",
            "Epoch 302/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4404\n",
            "Epoch 303/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4404\n",
            "Epoch 304/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4395\n",
            "Epoch 305/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4385\n",
            "Epoch 306/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4385\n",
            "Epoch 307/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4375\n",
            "Epoch 308/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4375\n",
            "Epoch 309/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4375\n",
            "Epoch 310/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4365\n",
            "Epoch 311/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4375\n",
            "Epoch 312/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4375\n",
            "Epoch 313/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4355\n",
            "Epoch 314/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4355\n",
            "Epoch 315/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4355\n",
            "Epoch 316/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4355\n",
            "Epoch 317/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4355\n",
            "Epoch 318/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4355\n",
            "Epoch 319/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4355\n",
            "Epoch 320/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4346\n",
            "Epoch 321/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4346\n",
            "Epoch 322/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4346\n",
            "Epoch 323/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4346\n",
            "Epoch 324/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4346\n",
            "Epoch 325/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4355\n",
            "Epoch 326/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4346\n",
            "Epoch 327/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4346\n",
            "Epoch 328/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4336\n",
            "Epoch 329/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4336\n",
            "Epoch 330/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4326\n",
            "Epoch 331/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4336\n",
            "Epoch 332/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4326\n",
            "Epoch 333/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4326\n",
            "Epoch 334/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4326\n",
            "Epoch 335/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4326\n",
            "Epoch 336/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4326\n",
            "Epoch 337/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4326\n",
            "Epoch 338/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4326\n",
            "Epoch 339/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4326\n",
            "Epoch 340/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4326\n",
            "Epoch 341/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4326\n",
            "Epoch 342/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4326\n",
            "Epoch 343/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4326\n",
            "Epoch 344/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4326\n",
            "Epoch 345/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4316\n",
            "Epoch 346/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4326\n",
            "Epoch 347/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4326\n",
            "Epoch 348/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4307\n",
            "Epoch 349/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4307\n",
            "Epoch 350/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4316\n",
            "Epoch 351/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4316\n",
            "Epoch 352/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4316\n",
            "Epoch 353/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4307\n",
            "Epoch 354/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4307\n",
            "Epoch 355/1000\n",
            "15/15 [==============================] - 0s 9ms/sample - loss: 8816.4307\n",
            "Epoch 356/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4316\n",
            "Epoch 357/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4307\n",
            "Epoch 358/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4307\n",
            "Epoch 359/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4307\n",
            "Epoch 360/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4307\n",
            "Epoch 361/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4307\n",
            "Epoch 362/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4307\n",
            "Epoch 363/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4307\n",
            "Epoch 364/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4297\n",
            "Epoch 365/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4297\n",
            "Epoch 366/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4297\n",
            "Epoch 367/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4287\n",
            "Epoch 368/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4287\n",
            "Epoch 369/1000\n",
            "15/15 [==============================] - 0s 5ms/sample - loss: 8816.4287\n",
            "Epoch 370/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4297\n",
            "Epoch 371/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4297\n",
            "Epoch 372/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4287\n",
            "Epoch 373/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4297\n",
            "Epoch 374/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4297\n",
            "Epoch 375/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4287\n",
            "Epoch 376/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4287\n",
            "Epoch 377/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4297\n",
            "Epoch 378/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4287\n",
            "Epoch 379/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4287\n",
            "Epoch 380/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4287\n",
            "Epoch 381/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4277\n",
            "Epoch 382/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4277\n",
            "Epoch 383/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4277\n",
            "Epoch 384/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4277\n",
            "Epoch 385/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4277\n",
            "Epoch 386/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4277\n",
            "Epoch 387/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4277\n",
            "Epoch 388/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4277\n",
            "Epoch 389/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4277\n",
            "Epoch 390/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4277\n",
            "Epoch 391/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4277\n",
            "Epoch 392/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4277\n",
            "Epoch 393/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4277\n",
            "Epoch 394/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4277\n",
            "Epoch 395/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4277\n",
            "Epoch 396/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4277\n",
            "Epoch 397/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4268\n",
            "Epoch 398/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4268\n",
            "Epoch 399/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4268\n",
            "Epoch 400/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4268\n",
            "Epoch 401/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4268\n",
            "Epoch 402/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4258\n",
            "Epoch 403/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4258\n",
            "Epoch 404/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4258\n",
            "Epoch 405/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4258\n",
            "Epoch 406/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4258\n",
            "Epoch 407/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4258\n",
            "Epoch 408/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4258\n",
            "Epoch 409/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4258\n",
            "Epoch 410/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4258\n",
            "Epoch 411/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4258\n",
            "Epoch 412/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4258\n",
            "Epoch 413/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4258\n",
            "Epoch 414/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4258\n",
            "Epoch 415/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4238\n",
            "Epoch 416/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4238\n",
            "Epoch 417/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4238\n",
            "Epoch 418/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4238\n",
            "Epoch 419/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4238\n",
            "Epoch 420/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4238\n",
            "Epoch 421/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4238\n",
            "Epoch 422/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4238\n",
            "Epoch 423/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4238\n",
            "Epoch 424/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4248\n",
            "Epoch 425/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4238\n",
            "Epoch 426/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4238\n",
            "Epoch 427/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4238\n",
            "Epoch 428/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4229\n",
            "Epoch 429/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4229\n",
            "Epoch 430/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4229\n",
            "Epoch 431/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4229\n",
            "Epoch 432/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4229\n",
            "Epoch 433/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4209\n",
            "Epoch 434/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4209\n",
            "Epoch 435/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4209\n",
            "Epoch 436/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4209\n",
            "Epoch 437/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4229\n",
            "Epoch 438/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4209\n",
            "Epoch 439/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4209\n",
            "Epoch 440/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4209\n",
            "Epoch 441/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4209\n",
            "Epoch 442/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4209\n",
            "Epoch 443/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4209\n",
            "Epoch 444/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4199\n",
            "Epoch 445/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4199\n",
            "Epoch 446/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4199\n",
            "Epoch 447/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4199\n",
            "Epoch 448/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4199\n",
            "Epoch 449/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4199\n",
            "Epoch 450/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4199\n",
            "Epoch 451/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4199\n",
            "Epoch 452/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4199\n",
            "Epoch 453/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4199\n",
            "Epoch 454/1000\n",
            "15/15 [==============================] - 0s 9ms/sample - loss: 8816.4199\n",
            "Epoch 455/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4199\n",
            "Epoch 456/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4189\n",
            "Epoch 457/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4189\n",
            "Epoch 458/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4189\n",
            "Epoch 459/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4180\n",
            "Epoch 460/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4180\n",
            "Epoch 461/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4180\n",
            "Epoch 462/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4180\n",
            "Epoch 463/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4180\n",
            "Epoch 464/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4180\n",
            "Epoch 465/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4180\n",
            "Epoch 466/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4180\n",
            "Epoch 467/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4180\n",
            "Epoch 468/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4180\n",
            "Epoch 469/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4180\n",
            "Epoch 470/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4180\n",
            "Epoch 471/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4180\n",
            "Epoch 472/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4180\n",
            "Epoch 473/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4170\n",
            "Epoch 474/1000\n",
            "15/15 [==============================] - 0s 9ms/sample - loss: 8816.4160\n",
            "Epoch 475/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4160\n",
            "Epoch 476/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4160\n",
            "Epoch 477/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4160\n",
            "Epoch 478/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4160\n",
            "Epoch 479/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4160\n",
            "Epoch 480/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4160\n",
            "Epoch 481/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4160\n",
            "Epoch 482/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4160\n",
            "Epoch 483/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4160\n",
            "Epoch 484/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4160\n",
            "Epoch 485/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4160\n",
            "Epoch 486/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4150\n",
            "Epoch 487/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4150\n",
            "Epoch 488/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4160\n",
            "Epoch 489/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4150\n",
            "Epoch 490/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4150\n",
            "Epoch 491/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4150\n",
            "Epoch 492/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4141\n",
            "Epoch 493/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4141\n",
            "Epoch 494/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4141\n",
            "Epoch 495/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4141\n",
            "Epoch 496/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4141\n",
            "Epoch 497/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4141\n",
            "Epoch 498/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4141\n",
            "Epoch 499/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4141\n",
            "Epoch 500/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4141\n",
            "Epoch 501/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4141\n",
            "Epoch 502/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4141\n",
            "Epoch 503/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4141\n",
            "Epoch 504/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4131\n",
            "Epoch 505/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4131\n",
            "Epoch 506/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4131\n",
            "Epoch 507/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4131\n",
            "Epoch 508/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4131\n",
            "Epoch 509/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4131\n",
            "Epoch 510/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4131\n",
            "Epoch 511/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4131\n",
            "Epoch 512/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4131\n",
            "Epoch 513/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4131\n",
            "Epoch 514/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4131\n",
            "Epoch 515/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4131\n",
            "Epoch 516/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4131\n",
            "Epoch 517/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4131\n",
            "Epoch 518/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4121\n",
            "Epoch 519/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4121\n",
            "Epoch 520/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4121\n",
            "Epoch 521/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4121\n",
            "Epoch 522/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4111\n",
            "Epoch 523/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4111\n",
            "Epoch 524/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4111\n",
            "Epoch 525/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4102\n",
            "Epoch 526/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4102\n",
            "Epoch 527/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4102\n",
            "Epoch 528/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4102\n",
            "Epoch 529/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4111\n",
            "Epoch 530/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4111\n",
            "Epoch 531/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4111\n",
            "Epoch 532/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4111\n",
            "Epoch 533/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4092\n",
            "Epoch 534/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4092\n",
            "Epoch 535/1000\n",
            "15/15 [==============================] - 0s 5ms/sample - loss: 8816.4092\n",
            "Epoch 536/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4092\n",
            "Epoch 537/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4092\n",
            "Epoch 538/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4092\n",
            "Epoch 539/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4092\n",
            "Epoch 540/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4092\n",
            "Epoch 541/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4092\n",
            "Epoch 542/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4092\n",
            "Epoch 543/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4092\n",
            "Epoch 544/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4092\n",
            "Epoch 545/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4092\n",
            "Epoch 546/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4092\n",
            "Epoch 547/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4082\n",
            "Epoch 548/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4082\n",
            "Epoch 549/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4082\n",
            "Epoch 550/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4082\n",
            "Epoch 551/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4072\n",
            "Epoch 552/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4072\n",
            "Epoch 553/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4082\n",
            "Epoch 554/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4082\n",
            "Epoch 555/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4072\n",
            "Epoch 556/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4082\n",
            "Epoch 557/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4082\n",
            "Epoch 558/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4072\n",
            "Epoch 559/1000\n",
            "15/15 [==============================] - 0s 9ms/sample - loss: 8816.4072\n",
            "Epoch 560/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4072\n",
            "Epoch 561/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4062\n",
            "Epoch 562/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4062\n",
            "Epoch 563/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4062\n",
            "Epoch 564/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4062\n",
            "Epoch 565/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4053\n",
            "Epoch 566/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4062\n",
            "Epoch 567/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4053\n",
            "Epoch 568/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4053\n",
            "Epoch 569/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4053\n",
            "Epoch 570/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4053\n",
            "Epoch 571/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4053\n",
            "Epoch 572/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4053\n",
            "Epoch 573/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4053\n",
            "Epoch 574/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4053\n",
            "Epoch 575/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4043\n",
            "Epoch 576/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4043\n",
            "Epoch 577/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4043\n",
            "Epoch 578/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4043\n",
            "Epoch 579/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4043\n",
            "Epoch 580/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4043\n",
            "Epoch 581/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4043\n",
            "Epoch 582/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4043\n",
            "Epoch 583/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4043\n",
            "Epoch 584/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4043\n",
            "Epoch 585/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4043\n",
            "Epoch 586/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4043\n",
            "Epoch 587/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4043\n",
            "Epoch 588/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4033\n",
            "Epoch 589/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4023\n",
            "Epoch 590/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4023\n",
            "Epoch 591/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4023\n",
            "Epoch 592/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4023\n",
            "Epoch 593/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4023\n",
            "Epoch 594/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4023\n",
            "Epoch 595/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4023\n",
            "Epoch 596/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4023\n",
            "Epoch 597/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4023\n",
            "Epoch 598/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4023\n",
            "Epoch 599/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4014\n",
            "Epoch 600/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4014\n",
            "Epoch 601/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4014\n",
            "Epoch 602/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4014\n",
            "Epoch 603/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4004\n",
            "Epoch 604/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4004\n",
            "Epoch 605/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4004\n",
            "Epoch 606/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4004\n",
            "Epoch 607/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4004\n",
            "Epoch 608/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4004\n",
            "Epoch 609/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4004\n",
            "Epoch 610/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4004\n",
            "Epoch 611/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4004\n",
            "Epoch 612/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4004\n",
            "Epoch 613/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4004\n",
            "Epoch 614/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4004\n",
            "Epoch 615/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4004\n",
            "Epoch 616/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4004\n",
            "Epoch 617/1000\n",
            "15/15 [==============================] - 0s 9ms/sample - loss: 8816.3994\n",
            "Epoch 618/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3994\n",
            "Epoch 619/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3994\n",
            "Epoch 620/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3994\n",
            "Epoch 621/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3994\n",
            "Epoch 622/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3994\n",
            "Epoch 623/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3984\n",
            "Epoch 624/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3994\n",
            "Epoch 625/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3984\n",
            "Epoch 626/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3984\n",
            "Epoch 627/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3984\n",
            "Epoch 628/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3984\n",
            "Epoch 629/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3984\n",
            "Epoch 630/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3975\n",
            "Epoch 631/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3965\n",
            "Epoch 632/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3965\n",
            "Epoch 633/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3965\n",
            "Epoch 634/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3965\n",
            "Epoch 635/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3965\n",
            "Epoch 636/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3965\n",
            "Epoch 637/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3965\n",
            "Epoch 638/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3965\n",
            "Epoch 639/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3965\n",
            "Epoch 640/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3965\n",
            "Epoch 641/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3965\n",
            "Epoch 642/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3965\n",
            "Epoch 643/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3965\n",
            "Epoch 644/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3965\n",
            "Epoch 645/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3955\n",
            "Epoch 646/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3945\n",
            "Epoch 647/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3955\n",
            "Epoch 648/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3945\n",
            "Epoch 649/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3955\n",
            "Epoch 650/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3955\n",
            "Epoch 651/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3955\n",
            "Epoch 652/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3955\n",
            "Epoch 653/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3955\n",
            "Epoch 654/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3955\n",
            "Epoch 655/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3955\n",
            "Epoch 656/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3945\n",
            "Epoch 657/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3955\n",
            "Epoch 658/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3936\n",
            "Epoch 659/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3926\n",
            "Epoch 660/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3926\n",
            "Epoch 661/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3936\n",
            "Epoch 662/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3926\n",
            "Epoch 663/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3926\n",
            "Epoch 664/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3926\n",
            "Epoch 665/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3926\n",
            "Epoch 666/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3926\n",
            "Epoch 667/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3926\n",
            "Epoch 668/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3926\n",
            "Epoch 669/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3926\n",
            "Epoch 670/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3936\n",
            "Epoch 671/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3926\n",
            "Epoch 672/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3916\n",
            "Epoch 673/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3916\n",
            "Epoch 674/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3916\n",
            "Epoch 675/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3916\n",
            "Epoch 676/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3916\n",
            "Epoch 677/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3916\n",
            "Epoch 678/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3916\n",
            "Epoch 679/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3916\n",
            "Epoch 680/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3916\n",
            "Epoch 681/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3906\n",
            "Epoch 682/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3916\n",
            "Epoch 683/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3916\n",
            "Epoch 684/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3906\n",
            "Epoch 685/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3906\n",
            "Epoch 686/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3896\n",
            "Epoch 687/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3877\n",
            "Epoch 688/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3877\n",
            "Epoch 689/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3877\n",
            "Epoch 690/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3896\n",
            "Epoch 691/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3896\n",
            "Epoch 692/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3896\n",
            "Epoch 693/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3896\n",
            "Epoch 694/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3896\n",
            "Epoch 695/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3877\n",
            "Epoch 696/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3877\n",
            "Epoch 697/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3877\n",
            "Epoch 698/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3877\n",
            "Epoch 699/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3877\n",
            "Epoch 700/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3867\n",
            "Epoch 701/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3867\n",
            "Epoch 702/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3867\n",
            "Epoch 703/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3867\n",
            "Epoch 704/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3867\n",
            "Epoch 705/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3867\n",
            "Epoch 706/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3867\n",
            "Epoch 707/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3867\n",
            "Epoch 708/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3867\n",
            "Epoch 709/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3867\n",
            "Epoch 710/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3867\n",
            "Epoch 711/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3867\n",
            "Epoch 712/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3867\n",
            "Epoch 713/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3867\n",
            "Epoch 714/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3857\n",
            "Epoch 715/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3857\n",
            "Epoch 716/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3848\n",
            "Epoch 717/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3848\n",
            "Epoch 718/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3848\n",
            "Epoch 719/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3848\n",
            "Epoch 720/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3848\n",
            "Epoch 721/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3848\n",
            "Epoch 722/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3838\n",
            "Epoch 723/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3838\n",
            "Epoch 724/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3848\n",
            "Epoch 725/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3848\n",
            "Epoch 726/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3838\n",
            "Epoch 727/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3828\n",
            "Epoch 728/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3828\n",
            "Epoch 729/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3828\n",
            "Epoch 730/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3828\n",
            "Epoch 731/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3828\n",
            "Epoch 732/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3828\n",
            "Epoch 733/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3828\n",
            "Epoch 734/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3828\n",
            "Epoch 735/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3828\n",
            "Epoch 736/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3828\n",
            "Epoch 737/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3828\n",
            "Epoch 738/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3828\n",
            "Epoch 739/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3828\n",
            "Epoch 740/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3828\n",
            "Epoch 741/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3809\n",
            "Epoch 742/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3809\n",
            "Epoch 743/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3809\n",
            "Epoch 744/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3809\n",
            "Epoch 745/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3818\n",
            "Epoch 746/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3818\n",
            "Epoch 747/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3818\n",
            "Epoch 748/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3818\n",
            "Epoch 749/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3818\n",
            "Epoch 750/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3799\n",
            "Epoch 751/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3799\n",
            "Epoch 752/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3809\n",
            "Epoch 753/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3809\n",
            "Epoch 754/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3799\n",
            "Epoch 755/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3789\n",
            "Epoch 756/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3789\n",
            "Epoch 757/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3789\n",
            "Epoch 758/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3789\n",
            "Epoch 759/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3789\n",
            "Epoch 760/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3789\n",
            "Epoch 761/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3789\n",
            "Epoch 762/1000\n",
            "15/15 [==============================] - 0s 9ms/sample - loss: 8816.3789\n",
            "Epoch 763/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3789\n",
            "Epoch 764/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3789\n",
            "Epoch 765/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3789\n",
            "Epoch 766/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3779\n",
            "Epoch 767/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3789\n",
            "Epoch 768/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3770\n",
            "Epoch 769/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3770\n",
            "Epoch 770/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3779\n",
            "Epoch 771/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3779\n",
            "Epoch 772/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3770\n",
            "Epoch 773/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3770\n",
            "Epoch 774/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3770\n",
            "Epoch 775/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3770\n",
            "Epoch 776/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3770\n",
            "Epoch 777/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3770\n",
            "Epoch 778/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3770\n",
            "Epoch 779/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3770\n",
            "Epoch 780/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3770\n",
            "Epoch 781/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3770\n",
            "Epoch 782/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3760\n",
            "Epoch 783/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3750\n",
            "Epoch 784/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3750\n",
            "Epoch 785/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3750\n",
            "Epoch 786/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3740\n",
            "Epoch 787/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3760\n",
            "Epoch 788/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3750\n",
            "Epoch 789/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3750\n",
            "Epoch 790/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3750\n",
            "Epoch 791/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3750\n",
            "Epoch 792/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3750\n",
            "Epoch 793/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3750\n",
            "Epoch 794/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3740\n",
            "Epoch 795/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3750\n",
            "Epoch 796/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3740\n",
            "Epoch 797/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3740\n",
            "Epoch 798/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3740\n",
            "Epoch 799/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3730\n",
            "Epoch 800/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3740\n",
            "Epoch 801/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3730\n",
            "Epoch 802/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3730\n",
            "Epoch 803/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3730\n",
            "Epoch 804/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3721\n",
            "Epoch 805/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3730\n",
            "Epoch 806/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3701\n",
            "Epoch 807/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3711\n",
            "Epoch 808/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3721\n",
            "Epoch 809/1000\n",
            "15/15 [==============================] - 0s 9ms/sample - loss: 8816.3760\n",
            "Epoch 810/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3740\n",
            "Epoch 811/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3701\n",
            "Epoch 812/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3711\n",
            "Epoch 813/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3682\n",
            "Epoch 814/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3721\n",
            "Epoch 815/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3691\n",
            "Epoch 816/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3711\n",
            "Epoch 817/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.2646\n",
            "Epoch 818/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8821.6807\n",
            "Epoch 819/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3760\n",
            "Epoch 820/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8817.8496\n",
            "Epoch 821/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.3740\n",
            "Epoch 822/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3770\n",
            "Epoch 823/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3809\n",
            "Epoch 824/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3857\n",
            "Epoch 825/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.3906\n",
            "Epoch 826/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.3984\n",
            "Epoch 827/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4092\n",
            "Epoch 828/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4180\n",
            "Epoch 829/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4287\n",
            "Epoch 830/1000\n",
            "15/15 [==============================] - 0s 9ms/sample - loss: 8816.4316\n",
            "Epoch 831/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4316\n",
            "Epoch 832/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4277\n",
            "Epoch 833/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4248\n",
            "Epoch 834/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4209\n",
            "Epoch 835/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4199\n",
            "Epoch 836/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4199\n",
            "Epoch 837/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4199\n",
            "Epoch 838/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4209\n",
            "Epoch 839/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4209\n",
            "Epoch 840/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4219\n",
            "Epoch 841/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4238\n",
            "Epoch 842/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4229\n",
            "Epoch 843/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4238\n",
            "Epoch 844/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4248\n",
            "Epoch 845/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4248\n",
            "Epoch 846/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4248\n",
            "Epoch 847/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4258\n",
            "Epoch 848/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4268\n",
            "Epoch 849/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4268\n",
            "Epoch 850/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4268\n",
            "Epoch 851/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4277\n",
            "Epoch 852/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4268\n",
            "Epoch 853/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4268\n",
            "Epoch 854/1000\n",
            "15/15 [==============================] - 0s 9ms/sample - loss: 8816.4277\n",
            "Epoch 855/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4277\n",
            "Epoch 856/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4287\n",
            "Epoch 857/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4268\n",
            "Epoch 858/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4277\n",
            "Epoch 859/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4277\n",
            "Epoch 860/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4277\n",
            "Epoch 861/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4277\n",
            "Epoch 862/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4277\n",
            "Epoch 863/1000\n",
            "15/15 [==============================] - 0s 9ms/sample - loss: 8816.4268\n",
            "Epoch 864/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4277\n",
            "Epoch 865/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4268\n",
            "Epoch 866/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4268\n",
            "Epoch 867/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4268\n",
            "Epoch 868/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4268\n",
            "Epoch 869/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4268\n",
            "Epoch 870/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4268\n",
            "Epoch 871/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4268\n",
            "Epoch 872/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4268\n",
            "Epoch 873/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4268\n",
            "Epoch 874/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4258\n",
            "Epoch 875/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4258\n",
            "Epoch 876/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4248\n",
            "Epoch 877/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4258\n",
            "Epoch 878/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4248\n",
            "Epoch 879/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4258\n",
            "Epoch 880/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4258\n",
            "Epoch 881/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4258\n",
            "Epoch 882/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4258\n",
            "Epoch 883/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4258\n",
            "Epoch 884/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4248\n",
            "Epoch 885/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4238\n",
            "Epoch 886/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4229\n",
            "Epoch 887/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4229\n",
            "Epoch 888/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4229\n",
            "Epoch 889/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4229\n",
            "Epoch 890/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4229\n",
            "Epoch 891/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4229\n",
            "Epoch 892/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4229\n",
            "Epoch 893/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4229\n",
            "Epoch 894/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4219\n",
            "Epoch 895/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4199\n",
            "Epoch 896/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4219\n",
            "Epoch 897/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4199\n",
            "Epoch 898/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4219\n",
            "Epoch 899/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4219\n",
            "Epoch 900/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4219\n",
            "Epoch 901/1000\n",
            "15/15 [==============================] - 0s 9ms/sample - loss: 8816.4219\n",
            "Epoch 902/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4219\n",
            "Epoch 903/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4209\n",
            "Epoch 904/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4209\n",
            "Epoch 905/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4189\n",
            "Epoch 906/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4180\n",
            "Epoch 907/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4180\n",
            "Epoch 908/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4180\n",
            "Epoch 909/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4180\n",
            "Epoch 910/1000\n",
            "15/15 [==============================] - 0s 9ms/sample - loss: 8816.4180\n",
            "Epoch 911/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4180\n",
            "Epoch 912/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4170\n",
            "Epoch 913/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4170\n",
            "Epoch 914/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4170\n",
            "Epoch 915/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4170\n",
            "Epoch 916/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4170\n",
            "Epoch 917/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4170\n",
            "Epoch 918/1000\n",
            "15/15 [==============================] - 0s 9ms/sample - loss: 8816.4170\n",
            "Epoch 919/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4160\n",
            "Epoch 920/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4160\n",
            "Epoch 921/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4160\n",
            "Epoch 922/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4160\n",
            "Epoch 923/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4160\n",
            "Epoch 924/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4160\n",
            "Epoch 925/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4160\n",
            "Epoch 926/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4160\n",
            "Epoch 927/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4150\n",
            "Epoch 928/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4150\n",
            "Epoch 929/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4150\n",
            "Epoch 930/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4141\n",
            "Epoch 931/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4141\n",
            "Epoch 932/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4141\n",
            "Epoch 933/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4131\n",
            "Epoch 934/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4141\n",
            "Epoch 935/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4141\n",
            "Epoch 936/1000\n",
            "15/15 [==============================] - 0s 9ms/sample - loss: 8816.4131\n",
            "Epoch 937/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4131\n",
            "Epoch 938/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4121\n",
            "Epoch 939/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4121\n",
            "Epoch 940/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4121\n",
            "Epoch 941/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4121\n",
            "Epoch 942/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4121\n",
            "Epoch 943/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4121\n",
            "Epoch 944/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4111\n",
            "Epoch 945/1000\n",
            "15/15 [==============================] - 0s 9ms/sample - loss: 8816.4111\n",
            "Epoch 946/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4111\n",
            "Epoch 947/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4111\n",
            "Epoch 948/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4111\n",
            "Epoch 949/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4111\n",
            "Epoch 950/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4111\n",
            "Epoch 951/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4111\n",
            "Epoch 952/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4102\n",
            "Epoch 953/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4092\n",
            "Epoch 954/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4092\n",
            "Epoch 955/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4092\n",
            "Epoch 956/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4092\n",
            "Epoch 957/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4092\n",
            "Epoch 958/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4092\n",
            "Epoch 959/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4082\n",
            "Epoch 960/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4072\n",
            "Epoch 961/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4072\n",
            "Epoch 962/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4082\n",
            "Epoch 963/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4072\n",
            "Epoch 964/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4072\n",
            "Epoch 965/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4072\n",
            "Epoch 966/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4072\n",
            "Epoch 967/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4072\n",
            "Epoch 968/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4062\n",
            "Epoch 969/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4062\n",
            "Epoch 970/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4062\n",
            "Epoch 971/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4062\n",
            "Epoch 972/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4062\n",
            "Epoch 973/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4062\n",
            "Epoch 974/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4062\n",
            "Epoch 975/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4062\n",
            "Epoch 976/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4043\n",
            "Epoch 977/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4043\n",
            "Epoch 978/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4043\n",
            "Epoch 979/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4043\n",
            "Epoch 980/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4043\n",
            "Epoch 981/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4043\n",
            "Epoch 982/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4043\n",
            "Epoch 983/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4043\n",
            "Epoch 984/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4033\n",
            "Epoch 985/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4033\n",
            "Epoch 986/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4023\n",
            "Epoch 987/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4023\n",
            "Epoch 988/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4023\n",
            "Epoch 989/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4023\n",
            "Epoch 990/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4023\n",
            "Epoch 991/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4023\n",
            "Epoch 992/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4023\n",
            "Epoch 993/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4014\n",
            "Epoch 994/1000\n",
            "15/15 [==============================] - 0s 9ms/sample - loss: 8816.4014\n",
            "Epoch 995/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4004\n",
            "Epoch 996/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4004\n",
            "Epoch 997/1000\n",
            "15/15 [==============================] - 0s 6ms/sample - loss: 8816.4014\n",
            "Epoch 998/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4014\n",
            "Epoch 999/1000\n",
            "15/15 [==============================] - 0s 8ms/sample - loss: 8816.4014\n",
            "Epoch 1000/1000\n",
            "15/15 [==============================] - 0s 7ms/sample - loss: 8816.4014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 9407.3603515625\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import yfinance as yf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Helper function to generate input data of appropriate shape\n",
        "def generate_time_series_data(data, batch_size):\n",
        "  # Generate batches of data\n",
        "  num_samples = data.shape[0]\n",
        "  num_batches = num_samples // batch_size\n",
        "  batchSet = []\n",
        "  for i in range(num_batches):\n",
        "    batchSet.append(data[i * batch_size:(i + 1) * batch_size])\n",
        "  return np.asarray(batchSet)\n",
        "\n",
        "#set the hyperparameters\n",
        "batch_size = 128\n",
        "latent_dim = 32\n",
        "learning_rate = 1e-1\n",
        "num_epochs = 1000\n",
        "beta = 0.005 #information bottleneck coefficient\n",
        "\n",
        "#Split the data into training and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(dataStocks, dataSPY, test_size=0.2)\n",
        "x_train = generate_time_series_data(x_train, batch_size)\n",
        "x_test = generate_time_series_data(x_test, batch_size)\n",
        "y_train = generate_time_series_data(y_train, batch_size)\n",
        "y_test = generate_time_series_data(y_test, batch_size)\n",
        "print(f\"shapes 1: {np.shape(x_train)} and {np.shape(y_train)}\")\n",
        "#Reshape the data to be 3D [samples, timesteps, features]\n",
        "# x_train = x_train.reshape((-1, 1, 1))\n",
        "# x_test = x_test.reshape(-1, 1, 1)\n",
        "\n",
        "#Build the model\n",
        "print(f\"test: {x_train.shape[1]} and {x_train.shape[2]}\")\n",
        "\n",
        "inputs = tf.keras.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
        "lstm_encoder = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = lstm_encoder(inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "z_mean = tf.keras.layers.Dense(latent_dim)(encoder_outputs)\n",
        "z_log_var = tf.keras.layers.Dense(latent_dim)(encoder_outputs)\n",
        "\n",
        "def sampling(args):\n",
        "  z_mean, z_log_var = args\n",
        "  epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "  return z_mean + tf.exp(0.5*z_log_var)*epsilon\n",
        "\n",
        "z = tf.keras.layers.Lambda(sampling)([z_mean, z_log_var])\n",
        "\n",
        "lstm_decoder = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = lstm_decoder(z, initial_state=encoder_states)\n",
        "print(f\"shapes 2: {np.shape(inputs)} and {np.shape(decoder_outputs)}\")\n",
        "decoder_outputs=tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1))(decoder_outputs)\n",
        "decoder_outputs=tf.squeeze(decoder_outputs, axis=[2]) #This fixes dimensionality issue (does it break anything?)\n",
        "print(f\"shapes 2: {np.shape(inputs)} and {np.shape(decoder_outputs)}\")\n",
        "\n",
        "#Define the loss\n",
        "def IBLoss(inputs, decoder_outputs):\n",
        "  print(f\"inputs: {inputs}\")\n",
        "  print(f\"{decoder_outputs}\")\n",
        "  print(f\"shapes 3: {np.shape(inputs)} and {np.shape(decoder_outputs)}\")\n",
        "  \n",
        "  reconstruction_loss = tf.keras.losses.MeanSquaredError()(inputs, decoder_outputs)\n",
        "  kl_loss = -0.5*tf.reduce_mean(z_log_var - tf.square(z_mean)-tf.exp(z_log_var) + 1)\n",
        "  information_bottleneck_loss = beta*kl_loss\n",
        "  loss = reconstruction_loss + information_bottleneck_loss\n",
        "  print(f\"shapes 4: {np.shape(loss)}\")\n",
        "  return loss\n",
        "\n",
        "#Define the optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "print(decoder_outputs)\n",
        "print(inputs)\n",
        "#Compile the model\n",
        "model = tf.keras.Model(inputs, decoder_outputs)\n",
        "model.compile(optimizer=optimizer, loss=IBLoss)\n",
        "\n",
        "#Train the model\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs)\n",
        "\n",
        "#Evaluate the model\n",
        "test_loss = model.evaluate(x_test, y_test)\n",
        "print(f'Test loss: {test_loss}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging with Xinyi's code"
      ],
      "metadata": {
        "id": "pltanC4pR2yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import datetime\n",
        "import math\n",
        "import numpy as np\n",
        "import statistics as stats\n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from pypfopt import risk_models\n",
        "from pypfopt import expected_returns\n",
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()\n",
        "\n",
        "#Helper function to generate input data of appropriate shape\n",
        "def generate_time_series_data(data, batch_size):\n",
        "  # Generate batches of data\n",
        "  num_samples = data.shape[0]\n",
        "  num_batches = num_samples // batch_size\n",
        "  batchSet = []\n",
        "  for i in range(num_batches):\n",
        "    batchSet.append(data[i * batch_size:(i + 1) * batch_size])\n",
        "  return np.asarray(batchSet)\n",
        "\n",
        "class timecallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        self.times = []\n",
        "        self.epochs = []\n",
        "        # use this value as reference to calculate cummulative time taken\n",
        "        self.timetaken = tf.timestamp()\n",
        "    def on_epoch_end(self,epoch,logs = {}):\n",
        "        self.times.append(tf.timestamp() - self.timetaken)\n",
        "        self.epochs.append(epoch)\n",
        "    def on_train_end(self,logs = {}):\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Total time taken until an epoch in seconds')\n",
        "        plt.plot(self.epochs, self.times, 'ro')\n",
        "        for i in range(len(self.epochs)):\n",
        "          j = self.times[i].numpy()\n",
        "          if i == 0:\n",
        "            plt.text(i, j, str(round(j, 3)))\n",
        "          else:\n",
        "            j_prev = self.times[i-1].numpy()\n",
        "            plt.text(i, j, str(round(j-j_prev, 3)))\n",
        "        plt.savefig(datetime.now().strftime(\"%Y%m%d%H%M%S\") + \".png\")"
      ],
      "metadata": {
        "id": "9cqXTg-bR-BT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data and create portfolios\n",
        "Portfolio_tickers = ['AVGO', 'COST', 'FDS', 'FTNT', 'ORLY', 'REGN', 'TMO', 'TSLA', 'UNH']\n",
        "Long_tickers = ['CPB', 'K']\n",
        "Portfolio = yf.download(Portfolio_tickers, start='2021-05-03', end='2022-07-12')['Adj Close']\n",
        "Long = yf.download(Long_tickers, start='2021-05-03', end='2022-07-12')['Adj Close']\n",
        "CPB = Long[['CPB']]\n",
        "K = Long[['K']]\n",
        "Portfolio1 = pd.concat([Portfolio, CPB], axis=1)\n",
        "Portfolio2 = pd.concat([Portfolio, K], axis=1)\n",
        "Portfolio3 = pd.concat([Portfolio, Long], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okzhLLSiSQbT",
        "outputId": "0313e42c-b539-49b4-b319-88e00d9b9f0c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  9 of 9 completed\n",
            "[*********************100%***********************]  2 of 2 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 60\n",
        "\n",
        "#Data preprocessing\n",
        "training_data_len = math.ceil(len(Portfolio3)* 0.8)\n",
        "temp = []\n",
        "tickers = Portfolio3.columns.values\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_data = scaler.fit_transform(Portfolio3)\n",
        "data = scaled_data.reshape(-1,11)\n",
        "print(f\"data shape: {data.shape}\")\n",
        "\n",
        "#Training data\n",
        "train_data = scaled_data[0: training_data_len, :]\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(batch_size, len(train_data)):\n",
        "    x_train.append(train_data[i-batch_size:i, :])\n",
        "    y_train.append(train_data[i, :])\n",
        "\n",
        "x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], x_train.shape[2]))\n",
        "print(f\"train_data shape: {train_data.shape}\")\n",
        "print(f\"x_train shape: {x_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "\n",
        "#Test data\n",
        "test_data = scaled_data[training_data_len-batch_size: , : ]\n",
        "y_test = data[training_data_len:]\n",
        "x_test = []\n",
        "\n",
        "for i in range(batch_size, len(test_data)):\n",
        "  x_test.append(test_data[i-batch_size:i, :])\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], x_test.shape[2]))\n",
        "\n",
        "print(f\"test data shape: {test_data.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYDfAJBeSjrQ",
        "outputId": "167d1d0d-068e-43c0-ab98-3a7f0e389940"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data shape: (300, 11)\n",
            "train_data shape: (240, 11)\n",
            "x_train shape: (180, 60, 11)\n",
            "y_train shape: (180, 11)\n",
            "test data shape: (120, 11)\n",
            "x_test shape: (60, 60, 11)\n",
            "y_test shape: (60, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set the hyperparameters\n",
        "latent_dim = 32\n",
        "learning_rate = 1e-2\n",
        "num_epochs = 10\n",
        "beta = 1 #information bottleneck coefficient\n",
        "n_stocks = np.shape(x_train)[2]\n",
        "\n",
        "#Build the model\n",
        "inputs = tf.keras.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
        "lstm_encoder = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = lstm_encoder(inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "z_mean = tf.keras.layers.Dense(latent_dim)(encoder_outputs)\n",
        "z_log_var = tf.keras.layers.Dense(latent_dim)(encoder_outputs)\n",
        "\n",
        "def sampling(args):\n",
        "  z_mean, z_log_var = args\n",
        "  epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "  return z_mean + tf.exp(0.5*z_log_var)*epsilon\n",
        "\n",
        "z = tf.keras.layers.Lambda(sampling)([z_mean, z_log_var])\n",
        "\n",
        "lstm_decoder = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = lstm_decoder(z, initial_state=encoder_states)\n",
        "decoder_outputs=tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_stocks))(decoder_outputs)\n",
        "\n",
        "#Define the losses for IB and no-IB\n",
        "def IBLoss(inputs, decoder_outputs):\n",
        "  reconstruction_loss = tf.keras.losses.MeanSquaredError()(inputs, decoder_outputs)\n",
        "  kl_loss = -0.5*tf.reduce_mean(z_log_var - tf.square(z_mean)-tf.exp(z_log_var) + 1)\n",
        "  information_bottleneck_loss = beta*kl_loss\n",
        "  loss = reconstruction_loss + information_bottleneck_loss\n",
        "  return loss\n",
        "\n",
        "def MSELoss(inputs, decoder_outputs):\n",
        "  reconstruction_loss = tf.keras.losses.MeanSquaredError()(inputs, decoder_outputs)\n",
        "  return reconstruction_loss\n",
        "\n",
        "#Define the optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "#Compile the model\n",
        "model = tf.keras.Model(inputs, decoder_outputs)\n",
        "model.compile(optimizer=optimizer, loss=IBLoss)\n",
        "\n",
        "model2 = tf.keras.Model(inputs, decoder_outputs)\n",
        "model2.compile(optimizer=optimizer, loss=MSELoss)\n",
        "\n",
        "# test_loss = model.evaluate(x_test, y_test)\n",
        "# print(f'Test loss: {test_loss}')"
      ],
      "metadata": {
        "id": "pnM7PV-5exjz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTEkOsrG7eXy",
        "outputId": "ba5d68f3-7a9a-4877-d1f7-982ab6c033ae"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 16080761550965785557\n",
              " xla_global_id: -1, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14415560704\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 12119195825351907165\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
              " xla_global_id: 416903419]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU mode\n",
        "#Train the model\n",
        "modelStart = datetime.now()\n",
        "model.fit(x_train, y_train, batch_size=1, epochs=num_epochs)\n",
        "modelEnd = datetime.now()\n",
        "print(f\"model 1 wall clock time: {modelEnd-modelStart}\")\n",
        "modelStart2 = datetime.now()\n",
        "model2.fit(x_train, y_train, batch_size=1, epochs=num_epochs)\n",
        "modelEnd2 = datetime.now()\n",
        "print(f\"model 1 wall clock time: {modelEnd2-modelStart2}\")\n",
        "\n",
        "#Evaluate the model\n",
        "predictions = np.mean(model.predict(x_test), axis=0)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
        "\n",
        "predictions2 = np.mean(model2.predict(x_test), axis=0)\n",
        "predictions2 = scaler.inverse_transform(predictions2)\n",
        "rmse2 = np.sqrt(np.mean(predictions2 - y_test)**2)\n",
        "\n",
        "print(f\"IB rmse: {rmse}\")\n",
        "print(f\"no IB rmse: {rmse2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ftaoti4q4hdX",
        "outputId": "6d3f2d4d-2a18-46be-8ef4-591561ed93a1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 19s 103ms/sample - loss: 0.0064\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 19s 104ms/sample - loss: 0.0065\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 19s 103ms/sample - loss: 0.0070\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 19s 105ms/sample - loss: 0.0063\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 19s 103ms/sample - loss: 0.0065\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 19s 104ms/sample - loss: 0.0059\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 18s 102ms/sample - loss: 0.0061\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 19s 103ms/sample - loss: 0.0060\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 19s 103ms/sample - loss: 0.0059\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 19s 103ms/sample - loss: 0.0056\n",
            "model 1 wall clock time: 0:03:06.060966\n",
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 37s 208ms/sample - loss: 0.0055\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 37s 208ms/sample - loss: 0.0056\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 37s 207ms/sample - loss: 0.0052\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 37s 208ms/sample - loss: 0.0054\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 37s 207ms/sample - loss: 0.0056\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 38s 209ms/sample - loss: 0.0052\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 37s 208ms/sample - loss: 0.0050\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 37s 208ms/sample - loss: 0.0048\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 37s 208ms/sample - loss: 0.0047\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 37s 208ms/sample - loss: 0.0046\n",
            "model 1 wall clock time: 0:06:13.985163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IB rmse: 367.23024755016235\n",
            "no IB rmse: 367.1228968366059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOuVB6yU76L1",
        "outputId": "9b29582b-e4ab-4d0c-c78e-e11b622e65f2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 2185597978877016199\n",
              " xla_global_id: -1, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 40231960576\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 5886719758418751024\n",
              " physical_device_desc: \"device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\"\n",
              " xla_global_id: 416903419]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU mode\n",
        "#Train the model\n",
        "modelStart_2 = datetime.now()\n",
        "model.fit(x_train, y_train, batch_size=1, epochs=num_epochs)\n",
        "modelEnd_2 = datetime.now()\n",
        "print(f\"model 1 wall clock time: {modelEnd_2-modelStart_2}\")\n",
        "modelStart2_2 = datetime.now()\n",
        "model2.fit(x_train, y_train, batch_size=1, epochs=num_epochs)\n",
        "modelEnd2_2 = datetime.now()\n",
        "print(f\"model 1 wall clock time: {modelEnd2_2-modelStart2_2}\")\n",
        "\n",
        "#Evaluate the model\n",
        "predictions = np.mean(model.predict(x_test), axis=0)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
        "\n",
        "predictions2 = np.mean(model2.predict(x_test), axis=0)\n",
        "predictions2 = scaler.inverse_transform(predictions2)\n",
        "rmse2 = np.sqrt(np.mean(predictions2 - y_test)**2)\n",
        "\n",
        "print(f\"IB rmse: {rmse}\")\n",
        "print(f\"no IB rmse: {rmse2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bva2YyGJ74zu",
        "outputId": "459aa345-c9cb-4f56-9800-a81eba5ca8f7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 19s 82ms/sample - loss: 0.0487\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 15s 81ms/sample - loss: 0.0277\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 15s 82ms/sample - loss: 0.0199\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 15s 82ms/sample - loss: 0.0203\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 15s 82ms/sample - loss: 0.0279\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 15s 82ms/sample - loss: 0.0182\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 15s 82ms/sample - loss: 0.0157\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 15s 81ms/sample - loss: 0.0130\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 15s 81ms/sample - loss: 0.0105\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 15s 81ms/sample - loss: 0.0096\n",
            "model 1 wall clock time: 0:02:31.591236\n",
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 34s 188ms/sample - loss: 0.0081\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 34s 187ms/sample - loss: 0.0093\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 34s 191ms/sample - loss: 0.0081\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 34s 189ms/sample - loss: 0.0072\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 34s 188ms/sample - loss: 0.0067\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 34s 187ms/sample - loss: 0.0066\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 34s 191ms/sample - loss: 0.0063\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 35s 193ms/sample - loss: 0.0064\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 35s 192ms/sample - loss: 0.0061\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 34s 188ms/sample - loss: 0.0059\n",
            "model 1 wall clock time: 0:05:42.302331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IB rmse: 376.9056872936421\n",
            "no IB rmse: 377.0957973673097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TPU\n",
        "import os\n",
        "try:\n",
        " device_name = os.environ[\"COLAB_TPU_ADDR\"]\n",
        " TPU_ADDRESS = \"grpc://\" + device_name\n",
        " print(\"Found TPU at: {}\".format(TPU_ADDRESS))\n",
        "except KeyError:\n",
        " print(\"TPU not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en4qJm22Mujf",
        "outputId": "7cc7c85b-5b2c-4aee-f6cd-76fc0af73948"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found TPU at: grpc://10.48.20.114:8470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TPU mode\n",
        "#Train the model\n",
        "modelStart_2 = datetime.now()\n",
        "model.fit(x_train, y_train, batch_size=1, epochs=num_epochs)\n",
        "modelEnd_2 = datetime.now()\n",
        "print(f\"model 1 wall clock time: {modelEnd_2-modelStart_2}\")\n",
        "modelStart2_2 = datetime.now()\n",
        "model2.fit(x_train, y_train, batch_size=1, epochs=num_epochs)\n",
        "modelEnd2_2 = datetime.now()\n",
        "print(f\"model 1 wall clock time: {modelEnd2_2-modelStart2_2}\")\n",
        "\n",
        "#Evaluate the model\n",
        "predictions = np.mean(model.predict(x_test), axis=0)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
        "\n",
        "predictions2 = np.mean(model2.predict(x_test), axis=0)\n",
        "predictions2 = scaler.inverse_transform(predictions2)\n",
        "rmse2 = np.sqrt(np.mean(predictions2 - y_test)**2)\n",
        "\n",
        "print(f\"IB rmse: {rmse}\")\n",
        "print(f\"no IB rmse: {rmse2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEKiP_3VB93n",
        "outputId": "c54f0d06-704f-403b-b92a-4438e8f55b08"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 7s 34ms/sample - loss: 0.0543\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 6s 32ms/sample - loss: 0.0386\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 6s 34ms/sample - loss: 0.0342\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 7s 40ms/sample - loss: 0.0269\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 6s 34ms/sample - loss: 0.0256\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 6s 34ms/sample - loss: 0.0267\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 6s 36ms/sample - loss: 0.0211\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 6s 35ms/sample - loss: 0.0197\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 6s 34ms/sample - loss: 0.0195\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 6s 36ms/sample - loss: 0.0180\n",
            "model 1 wall clock time: 0:01:04.604386\n",
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 14s 69ms/sample - loss: 0.0204\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 12s 66ms/sample - loss: 0.0163\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 12s 68ms/sample - loss: 0.0153\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 12s 67ms/sample - loss: 0.0129\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 12s 66ms/sample - loss: 0.0111\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 13s 72ms/sample - loss: 0.0107\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 15s 84ms/sample - loss: 0.0102\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 12s 69ms/sample - loss: 0.0087\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 12s 69ms/sample - loss: 0.0090\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 22s 125ms/sample - loss: 0.0076\n",
            "model 1 wall clock time: 0:02:18.003005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IB rmse: 381.8121098570966\n",
            "no IB rmse: 381.084415195407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Information Bottleneck Hyperparameter Search\n",
        "betaIB = [0.05, 0.1, 0.5,1, 1.5, 2, 2.5]\n",
        "rmseDict = {}\n",
        "for beta2 in betaIB:\n",
        "  #set the hyperparameters\n",
        "  latent_dim = 32\n",
        "  learning_rate = 1e-2\n",
        "  num_epochs = 10\n",
        "  n_stocks = np.shape(x_train)[2]\n",
        "\n",
        "  #Build the model\n",
        "  inputs = tf.keras.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
        "  lstm_encoder = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "  encoder_outputs, state_h, state_c = lstm_encoder(inputs)\n",
        "  encoder_states = [state_h, state_c]\n",
        "\n",
        "  z_mean = tf.keras.layers.Dense(latent_dim)(encoder_outputs)\n",
        "  z_log_var = tf.keras.layers.Dense(latent_dim)(encoder_outputs)\n",
        "\n",
        "  def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "    return z_mean + tf.exp(0.5*z_log_var)*epsilon\n",
        "\n",
        "  z = tf.keras.layers.Lambda(sampling)([z_mean, z_log_var])\n",
        "\n",
        "  lstm_decoder = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "  decoder_outputs, _, _ = lstm_decoder(z, initial_state=encoder_states)\n",
        "  decoder_outputs=tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_stocks))(decoder_outputs)\n",
        "\n",
        "  #Define the losses for IB and no-IB\n",
        "  def IBLoss(inputs, decoder_outputs):\n",
        "    reconstruction_loss = tf.keras.losses.MeanSquaredError()(inputs, decoder_outputs)\n",
        "    kl_loss = -0.5*tf.reduce_mean(z_log_var - tf.square(z_mean)-tf.exp(z_log_var) + 1)\n",
        "    information_bottleneck_loss = beta2*kl_loss\n",
        "    loss = reconstruction_loss + information_bottleneck_loss\n",
        "    return loss\n",
        "\n",
        "  def MSELoss(inputs, decoder_outputs):\n",
        "    reconstruction_loss = tf.keras.losses.MeanSquaredError()(inputs, decoder_outputs)\n",
        "    return reconstruction_loss\n",
        "\n",
        "  #Define the optimizer\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "  #Compile the model\n",
        "  model = tf.keras.Model(inputs, decoder_outputs)\n",
        "  model.compile(optimizer=optimizer, loss=IBLoss)\n",
        "\n",
        "  model2 = tf.keras.Model(inputs, decoder_outputs)\n",
        "  model2.compile(optimizer=optimizer, loss=MSELoss)\n",
        "\n",
        "  # test_loss = model.evaluate(x_test, y_test)\n",
        "  # print(f'Test loss: {test_loss}')\n",
        "\n",
        "  #Train the model\n",
        "  print(f\"beta2: {beta2}\")\n",
        "  modelStart_2 = datetime.now()\n",
        "  model.fit(x_train, y_train, batch_size=1, epochs=num_epochs)\n",
        "  modelEnd_2 = datetime.now()\n",
        "  print(f\"model 1 wall clock time: {modelEnd_2-modelStart_2}\")\n",
        "  modelStart2_2 = datetime.now()\n",
        "  model2.fit(x_train, y_train, batch_size=1, epochs=num_epochs)\n",
        "  modelEnd2_2 = datetime.now()\n",
        "  print(f\"model 1 wall clock time: {modelEnd2_2-modelStart2_2}\")\n",
        "\n",
        "  #Evaluate the model\n",
        "  predictions = np.mean(model.predict(x_test), axis=0)\n",
        "  predictions = scaler.inverse_transform(predictions)\n",
        "  rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
        "\n",
        "  predictions2 = np.mean(model2.predict(x_test), axis=0)\n",
        "  predictions2 = scaler.inverse_transform(predictions2)\n",
        "  rmse2 = np.sqrt(np.mean(predictions2 - y_test)**2)\n",
        "\n",
        "  print(f\"IB rmse: {rmse}\")\n",
        "  print(f\"no IB rmse: {rmse2}\")\n",
        "  rmseDict[\"IB_beta2\"+str(beta2)] = rmse\n",
        "  rmseDict[\"noIB_beta2\"+str(beta2)] = rmse2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igEYDWUBCckH",
        "outputId": "a842a126-74cd-4ffd-b3c7-dbd3b7214ce6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beta2: 0.05\n",
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 16s 37ms/sample - loss: 0.0417\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 7s 38ms/sample - loss: 0.0227\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 6s 36ms/sample - loss: 0.0180\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 7s 36ms/sample - loss: 0.0185\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 8s 42ms/sample - loss: 0.0185\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 6s 36ms/sample - loss: 0.0135\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 6s 35ms/sample - loss: 0.0131\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 6s 34ms/sample - loss: 0.0116\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0106\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 6s 35ms/sample - loss: 0.0103\n",
            "model 1 wall clock time: 0:01:16.568388\n",
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 18s 72ms/sample - loss: 0.0088\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 13s 72ms/sample - loss: 0.0089\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 12s 69ms/sample - loss: 0.0080\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 13s 70ms/sample - loss: 0.0077\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 14s 76ms/sample - loss: 0.0068\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 12s 69ms/sample - loss: 0.0074\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 12s 69ms/sample - loss: 0.0065\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 13s 71ms/sample - loss: 0.0060\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 12s 68ms/sample - loss: 0.0060\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 13s 70ms/sample - loss: 0.0058\n",
            "model 1 wall clock time: 0:02:13.178803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IB rmse: 387.64229893198853\n",
            "no IB rmse: 387.56168227577183\n",
            "beta2: 0.1\n",
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 16s 38ms/sample - loss: 0.0423\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0255\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0238\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 6s 36ms/sample - loss: 0.0200\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 7s 38ms/sample - loss: 0.0192\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 6s 36ms/sample - loss: 0.0179\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0184\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 6s 36ms/sample - loss: 0.0158\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 6s 35ms/sample - loss: 0.0120\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 6s 36ms/sample - loss: 0.0105\n",
            "model 1 wall clock time: 0:01:15.893461\n",
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 19s 74ms/sample - loss: 0.0100\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 13s 73ms/sample - loss: 0.0090\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 13s 71ms/sample - loss: 0.0083\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 13s 71ms/sample - loss: 0.0078\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 13s 71ms/sample - loss: 0.0070\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 13s 72ms/sample - loss: 0.0070\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 12s 69ms/sample - loss: 0.0061\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 13s 72ms/sample - loss: 0.0064\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 13s 73ms/sample - loss: 0.0056\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 12s 69ms/sample - loss: 0.0055\n",
            "model 1 wall clock time: 0:02:15.822238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IB rmse: 377.59492364600186\n",
            "no IB rmse: 377.425346902847\n",
            "beta2: 0.5\n",
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 18s 39ms/sample - loss: 0.0641\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 7s 40ms/sample - loss: 0.0282\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0232\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0217\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 6s 35ms/sample - loss: 0.0178\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0182\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 6s 35ms/sample - loss: 0.0214\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 7s 38ms/sample - loss: 0.0156\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 7s 38ms/sample - loss: 0.0179\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 6s 34ms/sample - loss: 0.0151\n",
            "model 1 wall clock time: 0:01:18.478911\n",
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 18s 71ms/sample - loss: 0.0144\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 13s 74ms/sample - loss: 0.0112\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 13s 72ms/sample - loss: 0.0115\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 13s 71ms/sample - loss: 0.0097\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 12s 69ms/sample - loss: 0.0086\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 13s 70ms/sample - loss: 0.0082\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 13s 70ms/sample - loss: 0.0078\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 13s 70ms/sample - loss: 0.0070\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 13s 71ms/sample - loss: 0.0068\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 12s 68ms/sample - loss: 0.0063\n",
            "model 1 wall clock time: 0:02:13.553920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IB rmse: 387.0544991603618\n",
            "no IB rmse: 387.12334515779645\n",
            "beta2: 1\n",
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 18s 39ms/sample - loss: 0.0501\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 6s 35ms/sample - loss: 0.0293\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 6s 35ms/sample - loss: 0.0253\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0221\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 7s 38ms/sample - loss: 0.0244\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 7s 38ms/sample - loss: 0.0163\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0153\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0149\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 7s 36ms/sample - loss: 0.0135\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 6s 36ms/sample - loss: 0.0142\n",
            "model 1 wall clock time: 0:01:17.686456\n",
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 19s 73ms/sample - loss: 0.0118\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 13s 71ms/sample - loss: 0.0113\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 13s 72ms/sample - loss: 0.0103\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 13s 71ms/sample - loss: 0.0106\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 13s 71ms/sample - loss: 0.0104\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 12s 69ms/sample - loss: 0.0097\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 13s 69ms/sample - loss: 0.0087\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 13s 71ms/sample - loss: 0.0081\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 13s 69ms/sample - loss: 0.0080\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 12s 68ms/sample - loss: 0.0075\n",
            "model 1 wall clock time: 0:02:14.207025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IB rmse: 379.5553608946942\n",
            "no IB rmse: 379.545185715704\n",
            "beta2: 1.5\n",
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 19s 38ms/sample - loss: 0.0462\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0325\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0233\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 7s 38ms/sample - loss: 0.0186\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0186\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 7s 38ms/sample - loss: 0.0185\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0183\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 7s 36ms/sample - loss: 0.0180\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0172\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0163\n",
            "model 1 wall clock time: 0:01:19.995295\n",
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 19s 73ms/sample - loss: 0.0138\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 13s 71ms/sample - loss: 0.0118\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 13s 73ms/sample - loss: 0.0104\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 13s 71ms/sample - loss: 0.0094\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 12s 69ms/sample - loss: 0.0088\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 13s 70ms/sample - loss: 0.0084\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 13s 73ms/sample - loss: 0.0078\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 13s 72ms/sample - loss: 0.0082\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 13s 73ms/sample - loss: 0.0079\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 13s 72ms/sample - loss: 0.0081\n",
            "model 1 wall clock time: 0:02:16.341933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IB rmse: 390.2098199290071\n",
            "no IB rmse: 389.9545787777176\n",
            "beta2: 2\n",
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 22s 43ms/sample - loss: 0.0515\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 7s 41ms/sample - loss: 0.0340\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0300\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0208\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 7s 38ms/sample - loss: 0.0171\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 7s 39ms/sample - loss: 0.0143\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0139\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0117\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0112\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 7s 39ms/sample - loss: 0.0104\n",
            "model 1 wall clock time: 0:01:24.144399\n",
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 19s 72ms/sample - loss: 0.0100\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 14s 76ms/sample - loss: 0.0096\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 14s 76ms/sample - loss: 0.0100\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 13s 72ms/sample - loss: 0.0094\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 13s 71ms/sample - loss: 0.0098\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 13s 71ms/sample - loss: 0.0087\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 13s 70ms/sample - loss: 0.0087\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 13s 74ms/sample - loss: 0.0090\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 13s 71ms/sample - loss: 0.0085\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 13s 72ms/sample - loss: 0.0094\n",
            "model 1 wall clock time: 0:02:17.816172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IB rmse: 374.10538375397863\n",
            "no IB rmse: 374.01742367258913\n",
            "beta2: 2.5\n",
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 19s 37ms/sample - loss: 0.0484\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0404\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 7s 38ms/sample - loss: 0.0251\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 6s 36ms/sample - loss: 0.0204\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 7s 38ms/sample - loss: 0.0194\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 6s 36ms/sample - loss: 0.0180\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 7s 37ms/sample - loss: 0.0175\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 7s 38ms/sample - loss: 0.0175\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 7s 38ms/sample - loss: 0.0174\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 7s 38ms/sample - loss: 0.0176\n",
            "model 1 wall clock time: 0:01:20.051136\n",
            "Train on 180 samples\n",
            "Epoch 1/10\n",
            "180/180 [==============================] - 20s 72ms/sample - loss: 0.0163\n",
            "Epoch 2/10\n",
            "180/180 [==============================] - 13s 72ms/sample - loss: 0.0149\n",
            "Epoch 3/10\n",
            "180/180 [==============================] - 13s 72ms/sample - loss: 0.0140\n",
            "Epoch 4/10\n",
            "180/180 [==============================] - 13s 73ms/sample - loss: 0.0115\n",
            "Epoch 5/10\n",
            "180/180 [==============================] - 13s 72ms/sample - loss: 0.0093\n",
            "Epoch 6/10\n",
            "180/180 [==============================] - 13s 73ms/sample - loss: 0.0090\n",
            "Epoch 7/10\n",
            "180/180 [==============================] - 13s 75ms/sample - loss: 0.0089\n",
            "Epoch 8/10\n",
            "180/180 [==============================] - 13s 72ms/sample - loss: 0.0078\n",
            "Epoch 9/10\n",
            "180/180 [==============================] - 13s 71ms/sample - loss: 0.0077\n",
            "Epoch 10/10\n",
            "180/180 [==============================] - 13s 70ms/sample - loss: 0.0070\n",
            "model 1 wall clock time: 0:02:17.971384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IB rmse: 376.51793688808766\n",
            "no IB rmse: 376.56695984586054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ele in list(rmseDict.keys()):\n",
        "  model = ele.split(\"_\")[0]\n",
        "  if model == \"IB\":\n",
        "    plt.plot(float(ele.split('beta2')[1]), rmseDict[ele], 'b.', label='IB')\n",
        "  elif model == \"noIB\":\n",
        "    plt.plot(float(ele.split('beta2')[1]), rmseDict[ele], 'r.', label='MSE')\n",
        "  plt.xlabel(\"IB beta\")\n",
        "  plt.ylabel(\"RMSE\")\n",
        "  # print(rmseDict[ele])\n",
        "  # plt.plot(float(ele.split('beta2')[1]), rmseDict[ele], 'b.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "qE3f5NYjMrOq",
        "outputId": "a372a1ab-cf61-4c7b-973d-855e74ae0f96"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calcSharpe(port):\n",
        "  mu = expected_returns.capm_return(port)\n",
        "  Sigma = risk_models.CovarianceShrinkage(port).ledoit_wolf()\n",
        "\n",
        "  ef = EfficientFrontier(mu, Sigma)\n",
        "  ef.max_sharpe()\n",
        "  weights = ef.clean_weights()\n",
        "\n",
        "  portfolio_mean = 0\n",
        "  portfolio_var = 0\n",
        "\n",
        "  for ticker in weights.keys():\n",
        "      portfolio_mean += weights[ticker]*mu[ticker]\n",
        "\n",
        "  for ticker1 in weights.keys():\n",
        "      for ticker2 in weights.keys():\n",
        "          portfolio_var += weights[ticker1]*weights[ticker2]*sigma[ticker1][ticker2]\n",
        "\n",
        "  portfolio_std = portfolio_var ** (1/2)\n",
        "\n",
        "  portfolio_sharpe = portfolio_mean/portfolio_std\n",
        "  return portfolio_sharpe"
      ],
      "metadata": {
        "id": "XeWOOQQ9dbzs"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calcSharpe()"
      ],
      "metadata": {
        "id": "BniC3FK-xrfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sharpe Ratios\\nPortfolio 1: {calcSharpe(Port1)}\\nPortfolio 2: {calcSharpe(Port2)}\\nPortfolio 3: {calcSharpe(Port3)}\")"
      ],
      "metadata": {
        "id": "tVz7XkXpeXva"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}